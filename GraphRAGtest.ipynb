{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce3abde4",
   "metadata": {},
   "source": [
    "# LangGraph test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c9f7e7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langgraph\n",
      "  Downloading langgraph-0.6.3-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: dotenv in c:\\users\\p\\desktop\\rag_embed\\first_pjt\\venv\\lib\\site-packages (0.9.9)\n",
      "Requirement already satisfied: langchain in c:\\users\\p\\desktop\\rag_embed\\first_pjt\\venv\\lib\\site-packages (0.3.27)\n",
      "Requirement already satisfied: langchain-openai in c:\\users\\p\\desktop\\rag_embed\\first_pjt\\venv\\lib\\site-packages (0.3.28)\n",
      "Requirement already satisfied: langchain-community in c:\\users\\p\\desktop\\rag_embed\\first_pjt\\venv\\lib\\site-packages (0.3.27)\n",
      "Requirement already satisfied: openai in c:\\users\\p\\desktop\\rag_embed\\first_pjt\\venv\\lib\\site-packages (1.97.1)\n",
      "Requirement already satisfied: faiss-cpu in c:\\users\\p\\desktop\\rag_embed\\first_pjt\\venv\\lib\\site-packages (1.11.0.post1)\n",
      "Requirement already satisfied: rank_bm25 in c:\\users\\p\\desktop\\rag_embed\\first_pjt\\venv\\lib\\site-packages (0.2.2)\n",
      "Requirement already satisfied: langchain-core>=0.1 in c:\\users\\p\\desktop\\rag_embed\\first_pjt\\venv\\lib\\site-packages (from langgraph) (0.3.72)\n",
      "Collecting langgraph-checkpoint<3.0.0,>=2.1.0 (from langgraph)\n",
      "  Downloading langgraph_checkpoint-2.1.1-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting langgraph-prebuilt<0.7.0,>=0.6.0 (from langgraph)\n",
      "  Downloading langgraph_prebuilt-0.6.3-py3-none-any.whl.metadata (4.5 kB)\n",
      "Collecting langgraph-sdk<0.3.0,>=0.2.0 (from langgraph)\n",
      "  Downloading langgraph_sdk-0.2.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in c:\\users\\p\\desktop\\rag_embed\\first_pjt\\venv\\lib\\site-packages (from langgraph) (2.11.7)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in c:\\users\\p\\desktop\\rag_embed\\first_pjt\\venv\\lib\\site-packages (from langgraph) (3.5.0)\n",
      "Collecting ormsgpack>=1.10.0 (from langgraph-checkpoint<3.0.0,>=2.1.0->langgraph)\n",
      "  Downloading ormsgpack-1.10.0-cp312-cp312-win_amd64.whl.metadata (44 kB)\n",
      "Requirement already satisfied: httpx>=0.25.2 in c:\\users\\p\\desktop\\rag_embed\\first_pjt\\venv\\lib\\site-packages (from langgraph-sdk<0.3.0,>=0.2.0->langgraph) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.10.1 in c:\\users\\p\\desktop\\rag_embed\\first_pjt\\venv\\lib\\site-packages (from langgraph-sdk<0.3.0,>=0.2.0->langgraph) (3.11.1)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\p\\desktop\\rag_embed\\first_pjt\\venv\\lib\\site-packages (from dotenv) (1.1.1)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in c:\\users\\p\\desktop\\rag_embed\\first_pjt\\venv\\lib\\site-packages (from langchain) (0.3.9)\n",
      "Requirement already satisfied: langsmith>=0.1.17 in c:\\users\\p\\desktop\\rag_embed\\first_pjt\\venv\\lib\\site-packages (from langchain) (0.4.8)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\p\\desktop\\rag_embed\\first_pjt\\venv\\lib\\site-packages (from langchain) (2.0.41)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\p\\desktop\\rag_embed\\first_pjt\\venv\\lib\\site-packages (from langchain) (2.32.4)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\p\\desktop\\rag_embed\\first_pjt\\venv\\lib\\site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\p\\desktop\\rag_embed\\first_pjt\\venv\\lib\\site-packages (from langchain-core>=0.1->langgraph) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\p\\desktop\\rag_embed\\first_pjt\\venv\\lib\\site-packages (from langchain-core>=0.1->langgraph) (1.33)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\p\\desktop\\rag_embed\\first_pjt\\venv\\lib\\site-packages (from langchain-core>=0.1->langgraph) (4.14.1)\n",
      "Requirement already satisfied: packaging>=23.2 in c:\\users\\p\\desktop\\rag_embed\\first_pjt\\venv\\lib\\site-packages (from langchain-core>=0.1->langgraph) (25.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\p\\desktop\\rag_embed\\first_pjt\\venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core>=0.1->langgraph) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\p\\desktop\\rag_embed\\first_pjt\\venv\\lib\\site-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\p\\desktop\\rag_embed\\first_pjt\\venv\\lib\\site-packages (from pydantic>=2.7.4->langgraph) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\p\\desktop\\rag_embed\\first_pjt\\venv\\lib\\site-packages (from pydantic>=2.7.4->langgraph) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\p\\desktop\\rag_embed\\first_pjt\\venv\\lib\\site-packages (from requests<3,>=2->langchain) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\p\\desktop\\rag_embed\\first_pjt\\venv\\lib\\site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\p\\desktop\\rag_embed\\first_pjt\\venv\\lib\\site-packages (from requests<3,>=2->langchain) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\p\\desktop\\rag_embed\\first_pjt\\venv\\lib\\site-packages (from requests<3,>=2->langchain) (2025.7.14)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\p\\desktop\\rag_embed\\first_pjt\\venv\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.3)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in c:\\users\\p\\desktop\\rag_embed\\first_pjt\\venv\\lib\\site-packages (from langchain-openai) (0.9.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\p\\desktop\\rag_embed\\first_pjt\\venv\\lib\\site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\p\\desktop\\rag_embed\\first_pjt\\venv\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\p\\desktop\\rag_embed\\first_pjt\\venv\\lib\\site-packages (from openai) (0.10.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\p\\desktop\\rag_embed\\first_pjt\\venv\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\p\\desktop\\rag_embed\\first_pjt\\venv\\lib\\site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\p\\desktop\\rag_embed\\first_pjt\\venv\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.0->langgraph) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\p\\desktop\\rag_embed\\first_pjt\\venv\\lib\\site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.0->langgraph) (0.16.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\p\\desktop\\rag_embed\\first_pjt\\venv\\lib\\site-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\p\\desktop\\rag_embed\\first_pjt\\venv\\lib\\site-packages (from langchain-community) (3.12.15)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\p\\desktop\\rag_embed\\first_pjt\\venv\\lib\\site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in c:\\users\\p\\desktop\\rag_embed\\first_pjt\\venv\\lib\\site-packages (from langchain-community) (2.10.1)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\users\\p\\desktop\\rag_embed\\first_pjt\\venv\\lib\\site-packages (from langchain-community) (0.4.1)\n",
      "Requirement already satisfied: numpy>=1.26.2 in c:\\users\\p\\desktop\\rag_embed\\first_pjt\\venv\\lib\\site-packages (from langchain-community) (2.3.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\p\\desktop\\rag_embed\\first_pjt\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\p\\desktop\\rag_embed\\first_pjt\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\p\\desktop\\rag_embed\\first_pjt\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\p\\desktop\\rag_embed\\first_pjt\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\p\\desktop\\rag_embed\\first_pjt\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\p\\desktop\\rag_embed\\first_pjt\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\p\\desktop\\rag_embed\\first_pjt\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\p\\desktop\\rag_embed\\first_pjt\\venv\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\p\\desktop\\rag_embed\\first_pjt\\venv\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\p\\desktop\\rag_embed\\first_pjt\\venv\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.1.0)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\p\\desktop\\rag_embed\\first_pjt\\venv\\lib\\site-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\p\\desktop\\rag_embed\\first_pjt\\venv\\lib\\site-packages (from langsmith>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\p\\desktop\\rag_embed\\first_pjt\\venv\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Downloading langgraph-0.6.3-py3-none-any.whl (152 kB)\n",
      "Downloading langgraph_checkpoint-2.1.1-py3-none-any.whl (43 kB)\n",
      "Downloading langgraph_prebuilt-0.6.3-py3-none-any.whl (28 kB)\n",
      "Downloading langgraph_sdk-0.2.0-py3-none-any.whl (50 kB)\n",
      "Downloading ormsgpack-1.10.0-cp312-cp312-win_amd64.whl (121 kB)\n",
      "Installing collected packages: ormsgpack, langgraph-sdk, langgraph-checkpoint, langgraph-prebuilt, langgraph\n",
      "\n",
      "   -------- ------------------------------- 1/5 [langgraph-sdk]\n",
      "   ---------------- ----------------------- 2/5 [langgraph-checkpoint]\n",
      "   -------------------------------- ------- 4/5 [langgraph]\n",
      "   -------------------------------- ------- 4/5 [langgraph]\n",
      "   -------------------------------- ------- 4/5 [langgraph]\n",
      "   -------------------------------- ------- 4/5 [langgraph]\n",
      "   ---------------------------------------- 5/5 [langgraph]\n",
      "\n",
      "Successfully installed langgraph-0.6.3 langgraph-checkpoint-2.1.1 langgraph-prebuilt-0.6.3 langgraph-sdk-0.2.0 ormsgpack-1.10.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install langgraph dotenv langchain langchain-openai langchain-community openai faiss-cpu rank_bm25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57088542",
   "metadata": {},
   "source": [
    "# set env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b34b6d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"OPENAI_API_BASE\"] = os.getenv(\"OPENAI_API_BASE\")\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "faiss_store = (\n",
    "    FAISS.load_local(\n",
    "        \"faiss_store\", embeddings=embeddings, allow_dangerous_deserialization=True\n",
    "    )\n",
    "    if os.path.exists(\"faiss_store\")\n",
    "    else None\n",
    ")\n",
    "\n",
    "all_docs = list(faiss_store.docstore._dict.values())\n",
    "\n",
    "\n",
    "all_texts = [doc.page_content for doc in faiss_store.docstore._dict.values()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3574d6",
   "metadata": {},
   "source": [
    "# FAISS + ensemble[bm25 / similarity]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7d1e576c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ BM25 캐시 생성 완료! 대상: ['집', '나무', '사람', '공통 구조 해석']\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.retrievers import BM25Retriever\n",
    "from langchain.retrievers import EnsembleRetriever\n",
    "\n",
    "common_docs = [doc for doc in all_docs if doc.metadata.get(\"main_topic\") == \"공통 구조 해석\"]\n",
    "\n",
    "# 나머지 카테고리별로 문서 그룹화\n",
    "specific_docs_grouped = defaultdict(list)\n",
    "for doc in all_docs:\n",
    "    category = doc.metadata.get(\"main_topic\")\n",
    "    if category and category != \"공통 구조 해석\":\n",
    "        specific_docs_grouped[category].append(doc)\n",
    "\n",
    "# BM25 리트리버 캐시 생성: 각 카테고리에 '공통' 문서를 합쳐서 생성\n",
    "bm25_retriever_cache = {}\n",
    "for category, docs in specific_docs_grouped.items():\n",
    "    # 해당 카테고리 문서와 공통 문서를 합칩니다.\n",
    "    combined_docs = docs + common_docs\n",
    "    bm25_retriever_cache[category] = BM25Retriever.from_documents(combined_docs)\n",
    "\n",
    "# '공통 해석 사항' 자체에 대한 리트리버도 추가 (필요 시 사용)\n",
    "if common_docs:\n",
    "    bm25_retriever_cache[\"공통 구조 해석\"] = BM25Retriever.from_documents(common_docs)\n",
    "\n",
    "print(f\"✅ BM25 캐시 생성 완료! 대상: {list(bm25_retriever_cache.keys())}\")\n",
    "\n",
    "def get_ensemble_retriever_by_category(\n",
    "    faiss_store: FAISS,\n",
    "    bm25_cache: dict,\n",
    "    category: str,\n",
    "    k: int = 3,\n",
    "    weights: list[float] = [0.3, 0.7]\n",
    "):\n",
    "    \"\"\"\n",
    "    지정된 카테고리(+공통)에 맞는 리트리버를 동적으로 조합하여 반환합니다.\n",
    "    \"\"\"\n",
    "    # 1. 캐시에서 미리 생성된 BM25 리트리버를 가져옵니다.\n",
    "    # 이 리트리버는 이미 '공통' 문서를 포함하고 있습니다.\n",
    "    sparse_bm25_retriever = bm25_cache.get(category)\n",
    "    if not sparse_bm25_retriever:\n",
    "        raise ValueError(f\"'{category}' 카테고리에 대한 BM25 리트리버가 캐시에 없습니다.\")\n",
    "    sparse_bm25_retriever.k = k\n",
    "\n",
    "    # 2. FAISS 리트리버는 'filter'와 '$in'을 사용하여 동적으로 생성합니다.\n",
    "    # '공통'과 '지정된 카테고리'를 모두 포함하도록 필터링합니다.\n",
    "    search_categories = [\"공통 구조 해석\", category]\n",
    "    # 만약 카테고리가 '공통 해석 사항'이라면 중복을 피합니다.\n",
    "    if category == \"공통 구조 해석\":\n",
    "        search_categories = [\"공통 구조 해석\"]\n",
    "    \n",
    "    dense_similarity_retriever = faiss_store.as_retriever(\n",
    "        search_type=\"similarity\",\n",
    "        search_kwargs={\n",
    "            \"k\": k, \n",
    "            # 중요: 메타데이터 키를 'main_topic'으로 통일합니다.\n",
    "            \"filter\": {\"main_topic\": {\"$in\": search_categories}}\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # 3. 두 리트리버를 앙상블로 묶습니다.\n",
    "    return EnsembleRetriever(\n",
    "        retrievers=[sparse_bm25_retriever, dense_similarity_retriever],\n",
    "        weights=weights,\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "K = 3\n",
    "weights = [0.3, 0.7]\n",
    "\n",
    "# Sparse\n",
    "sparse_bm25_retriever = BM25Retriever.from_texts(texts=all_texts)\n",
    "sparse_bm25_retriever.k = K  # k값을 통일하여 설정\n",
    "# Dense\n",
    "dense_similarity_retriever = faiss_store.as_retriever(\n",
    "    search_type=\"similarity\", search_kwargs={\"k\": K}\n",
    ")\n",
    "\n",
    "retriever = EnsembleRetriever(\n",
    "    retrievers=[sparse_bm25_retriever, dense_similarity_retriever],\n",
    "    weights=weights,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43dd2dfd",
   "metadata": {},
   "source": [
    "# state 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a00c52f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, TypedDict\n",
    "\n",
    "class GraphState(TypedDict):\n",
    "    \"\"\"\n",
    "    Graph RAG 파이프라인의 상태\n",
    "\n",
    "    Attributes:\n",
    "        original_question (str): 사용자가 입력한 원본 질문 (그림 묘사)\n",
    "        decomposed_questions (List[str]): 의미 단위로 분해된 질문 리스트\n",
    "        retrieved_contexts (List[str]): 검색된 관련 문서(해석) 조각 리스트\n",
    "        generation (str): LLM이 생성한 최종 해석\n",
    "        relevance_check (str): 질문의 HTP 검사 관련성 여부 (\"yes\" or \"no\")\n",
    "        hallucination_check (str): 생성된 답변의 환각 현상 유무 (\"yes\" or \"no\")\n",
    "        category (str): 질문 범주(집, 나무, 사람)\n",
    "    \"\"\"\n",
    "    original_question: str\n",
    "    decomposed_questions: List[str]\n",
    "    retrieved_contexts: List[str]\n",
    "    generation: str\n",
    "    relevance_check: str\n",
    "    hallucination_check: str\n",
    "    category: str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b794cc",
   "metadata": {},
   "source": [
    "# 실행 시간 체크"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bade9340",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import functools\n",
    "\n",
    "execution_times = {}\n",
    "\n",
    "def timing_decorator(func):\n",
    "    \"\"\"\n",
    "    각 노드 실행 시간 측정\n",
    "    \"\"\"\n",
    "    @functools.wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start_time = time.time()\n",
    "        result = func(*args, **kwargs)\n",
    "        end_time = time.time()\n",
    "        elapsed_time = end_time - start_time\n",
    "        print(f\"Execution time for {func.__name__}: {elapsed_time:.2f} seconds\")\n",
    "        execution_times[func.__name__] = elapsed_time\n",
    "        return result\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cad33d1",
   "metadata": {},
   "source": [
    "# 노드 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9091b8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser, JsonOutputParser\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "# 2-1. Relevance Check Node (질문 관련성 검사)\n",
    "@timing_decorator\n",
    "def relevance_check_node(state: GraphState):\n",
    "    \"\"\"\n",
    "    입력된 질문이 HTP 심리검사 해석과 관련이 있는지 확인합니다.\n",
    "    \"\"\"\n",
    "    print(\"--- 1. 질문 관련성 검사 시작 ---\")\n",
    "    question = state[\"original_question\"]\n",
    "    \n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "        \"\"\"당신은 심리검사 전문가입니다. 주어진 질문이 'HTP(집-나무-사람) 그림 심리검사' 해석과 관련된 내용인지 판단해주세요.\n",
    "        HTP 검사는 집, 나무, 사람 그림의 특징(예: 지붕, 문, 창문, 나무 기둥, 가지, 사람의 눈, 코, 입 등)을 분석하는 것입니다.\n",
    "        질문은 HTP 그림에 대한 관찰 묘사로, 그림의 요소나 특징에 대한 내용입니다.\n",
    "        이에 해당하면 'yes', 전혀 관련 없는 내용(예: 오늘 날씨, 스포츠 경기 결과 등)이면 'no'로만 대답해주세요.\n",
    "\n",
    "        질문: {question}\n",
    "        판단 (yes/no):\"\"\"\n",
    "    )\n",
    "    \n",
    "    chain = prompt | llm | StrOutputParser()\n",
    "    relevance = chain.invoke({\"question\": question})\n",
    "    \n",
    "    print(f\"질문 관련성: {relevance}\")\n",
    "    state[\"relevance_check\"] = relevance.lower()\n",
    "    if state[\"relevance_check\"] == \"no\":\n",
    "        # print(\"질문이 HTP 검사와 관련이 없습니다. 프로세스를 종료합니다.\")\n",
    "        state[\"generation\"] = \"관찰 결과를 다시 입력해주세요.\"\n",
    "        print(state)\n",
    "    return state\n",
    "\n",
    "# 2-2. Decompose Node (질문 분해)\n",
    "@timing_decorator\n",
    "def decompose_query_node(state: GraphState):\n",
    "    \"\"\"\n",
    "    입력된 질문을 의미 단위의 여러 하위 질문으로 분해합니다.\n",
    "    \"\"\"\n",
    "    print(\"--- 2. 질문 분해 시작 ---\")\n",
    "    question = state[\"original_question\"]\n",
    "    \n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "        \"\"\"당신은 HTP 그림 심리검사 문장 분석 전문가입니다. 상담사가 그림을 보고 관찰한 내용을 나열한 문장이 주어집니다. \n",
    "        이 문장을 그림의 각 요소(예: 문, 창문, 지붕, 길 등)에 대한 독립적인 해석이 가능한 단위로 분해하여 JSON 리스트 형태로 반환해주세요.\n",
    "\n",
    "        예시:\n",
    "        입력: \"집에 창문은 2개 존재하고 크기는 적절함. 문은 집의 크기에 비해 작으며 문과 바깥이 길로 이어져 있지 않음.\"\n",
    "        출력: {{\"queries\": [\"집 창문의 개수는 2개이고 크기는 적절하다.\", \"집 문의 크기가 집 전체에 비해 작다.\", \"집과 외부를 잇는 길이 그려져 있지 않다.\"]}}\n",
    "\n",
    "        입력: {question}\n",
    "        출력:\"\"\"\n",
    "    )\n",
    "    \n",
    "    chain = prompt | llm | JsonOutputParser()\n",
    "    decomposed = chain.invoke({\"question\": question})\n",
    "    \n",
    "    decomposed_questions = decomposed.get(\"queries\", [])\n",
    "    print(f\"분해된 질문: {decomposed_questions}\")\n",
    "    state[\"decomposed_questions\"] = decomposed_questions\n",
    "    return state\n",
    "\n",
    "# 2-3. Retrieve Node (정보 검색)\n",
    "@timing_decorator\n",
    "def meta_retrieve_node(state: GraphState, config: RunnableConfig):\n",
    "    \"\"\"\n",
    "    분해된 각 질문에 대해, state의 category에 맞춰 동적으로 Ensemble Retriever를\n",
    "    생성하고 관련 문서를 검색합니다.\n",
    "    \"\"\"\n",
    "    print(f\"--- 3. 정보 검색 시작 (카테고리: {state['category']}) ---\")\n",
    "    \n",
    "    # FastAPI의 app.state에 저장해 둔 구성요소를 config를 통해 가져옵니다.\n",
    "    faiss_store = config[\"configurable\"][\"faiss_store\"]\n",
    "    bm25_cache = config[\"configurable\"][\"bm25_retriever_cache\"]\n",
    "    \n",
    "    # 현재 요청의 카테고리에 맞는 앙상블 리트리버를 즉시 생성합니다.\n",
    "    try:\n",
    "        retriever = get_ensemble_retriever_by_category(\n",
    "            faiss_store=faiss_store,\n",
    "            bm25_cache=bm25_cache,\n",
    "            category=state[\"category\"]\n",
    "        )\n",
    "    except ValueError as e:\n",
    "        # 특정 카테고리가 없는 경우에 대한 예외 처리\n",
    "        print(e)\n",
    "        state[\"retrieved_contexts\"] = []\n",
    "        # 또는 에러 메시지를 generation에 담아 사용자에게 전달할 수도 있습니다.\n",
    "        state[\"generation\"] = \"죄송합니다. 요청하신 카테고리의 정보를 찾을 수 없습니다.\"\n",
    "        return state\n",
    "\n",
    "    decomposed_questions = state[\"decomposed_questions\"]\n",
    "    all_retrieved_docs = []\n",
    "    for query in decomposed_questions:\n",
    "        print(f\"  - 검색 쿼리: '{query}'\")\n",
    "        retrieved_docs = retriever.invoke(query)\n",
    "        doc_texts = [doc.page_content for doc in retrieved_docs]\n",
    "        all_retrieved_docs.extend(doc_texts)\n",
    "    \n",
    "    unique_contexts = list(set(all_retrieved_docs))\n",
    "    print(f\"검색된 해석 Context 수: {len(unique_contexts)}\")\n",
    "    state[\"retrieved_contexts\"] = unique_contexts\n",
    "    return state\n",
    "\n",
    "@timing_decorator\n",
    "def retrieve_node(state: GraphState):\n",
    "    \"\"\"\n",
    "    분해된 각 질문에 대해 Ensemble Retriever를 사용하여 관련 문서를 검색합니다.\n",
    "    \"\"\"\n",
    "    print(\"--- 3. 정보 검색 시작 ---\")\n",
    "    decomposed_questions = state[\"decomposed_questions\"]\n",
    "    all_retrieved_docs = []\n",
    "\n",
    "    for query in decomposed_questions:\n",
    "        print(f\"  - 검색 쿼리: '{query}'\")\n",
    "        # 여기서 사용자가 제공한 retriever를 사용합니다.\n",
    "        retrieved_docs = retriever.invoke(query)\n",
    "        \n",
    "        # 검색 결과의 내용을 문자열로 변환하여 추가\n",
    "        doc_texts = [doc.page_content for doc in retrieved_docs]\n",
    "        all_retrieved_docs.extend(doc_texts)\n",
    "    \n",
    "    # 중복 제거\n",
    "    unique_contexts = list(set(all_retrieved_docs))\n",
    "    print(f\"검색된 해석 Context 수: {len(unique_contexts)}\")\n",
    "    state[\"retrieved_contexts\"] = unique_contexts\n",
    "    return state\n",
    "\n",
    "# 2-4. Generate Node (답변 생성)\n",
    "@timing_decorator\n",
    "def generate_node(state: GraphState):\n",
    "    \"\"\"\n",
    "    검색된 Context를 바탕으로 최종 해석 답변을 생성합니다.\n",
    "    \"\"\"\n",
    "    print(\"--- 4. 답변 생성 시작 ---\")\n",
    "    question = state[\"original_question\"]\n",
    "    contexts = \"\\n\\n\".join(state[\"retrieved_contexts\"])\n",
    "    \n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "        \"\"\"당신은 HTP 그림 심리검사 결과 해석 전문가입니다.\n",
    "        상담사가 관찰한 '그림 특징'과 그에 대한 '해석 참고자료'가 주어집니다. \n",
    "        두 정보를 종합하여, 내담자의 심리상태에 대한 최종 해석 보고서를 작성해주세요.\n",
    "        ## 유의사항\n",
    "        전문적이고 이해하기 쉬운 말투로 설명하고, 각 특징과 해석을 논리적으로 연결하여 설명해주세요.\n",
    "        정보는 반드시 주어진 '해석 참고자료'에 근거해야 하며, 환각(hallucination)이 없어야 합니다.\n",
    "        답변은 질문에 대한 관찰 내용과 관련된 것만 작성해야 합니다.\n",
    "        각 특징에 대한 해석 내용을 분석하고 참고 자료에서 관련 내용을 찾아 종합적으로 해석하세요.\n",
    "        답변은 너무 극단적이지 않고 충분히 납득할 수 있는 수준으로 작성해야 합니다.\n",
    "        참고자료가 너무 적거나 관련성이 낮다면, 답변은 간단하게 작성해주세요.\n",
    "        특이한 관찰결과가 아니라면 부정적인 해석을 하면 안됩니다.\n",
    "        \n",
    "        [보고서 작성 지침]\n",
    "\n",
    "        서론: 그림의 전반적인 특징을 간략히 요약하며 해석을 시작합니다.\n",
    "        본론 (구조적 특징별 해석):\n",
    "        입력된 그림 묘사를 바탕으로, 주요 구조적 특징별로 소제목을 나누어 분석합니다.\n",
    "        각 특징에 대한 해석은 반드시 **참고할 해석 내용(RAG 검색 결과)**에 근거하여 작성해야 합니다. 문서에 없는 내용을 추측하거나 환각(hallucination)을 생성해서는 안 됩니다. 각 해석은 전문가적인 용어와 어조를 사용하되, 이해하기 쉽게 풀어 설명합니다.\n",
    "        종합 소견:\n",
    "        위에서 분석된 개별 해석들을 종합하여, 해당 그림이 시사하는 핵심적인 심리 상태에 대한 통합적인 가설을 제시합니다.\n",
    "        여러 특징이 공통적으로 가리키는 심리적 주제(예: 불안, 위축, 방어 등)를 중심으로 요약합니다.\n",
    "\n",
    "\n",
    "        출력 형식: 아래의 마크다운 형식을 반드시 준수하여 보고서를 작성하세요.\n",
    "\n",
    "        ## 상담사의 그림 특징 관찰 내용:\n",
    "        {question}\n",
    "\n",
    "        ## 해석 참고자료:\n",
    "        {context}\n",
    "\n",
    "        ## 최종 해석 보고서:\n",
    "        [출력 보고서 형식 예시]\n",
    "        관찰 결과 : {question}\n",
    "\n",
    "        주요 특징 및 해석적 가설\n",
    "        입력해주신 그림의 묘사를 바탕으로, 주요 구조적 특징에 대한 심리적 의미를 아래와 같이 분석할 수 있습니다.\n",
    "        [질문 개수에 맞추어 생성합니다.]\n",
    "        특징 1:\n",
    "        (해당하는 묘사가 있을 경우, 해석 내용을 여기에 작성)\n",
    "        특징 2:\n",
    "        (해당하는 묘사가 있을 경우, 내용을 여기에 작성)\n",
    "        특징 3:\n",
    "        (해당하는 묘사가 있을 경우, 내용을 여기에 작성)\n",
    "        특징 4:\n",
    "        (해당하는 묘사가 있을 경우, 내용을 여기에 작성)\n",
    "        ...\n",
    "\n",
    "        종합 소견\n",
    "        종합적으로 볼 때, (예: 외부 세계와의 관계에서의 위축감과 방어적 태도) ~~ 특징과 ~~ 특징이 공통적으로 ~~한 내면 상태를 반영할 가능성을 보여줍니다. 이는 ~~ 어려움으로 이어질 수 있음을 암시합니다.\n",
    "        \n",
    "        \"\"\"\n",
    "    )\n",
    "    \n",
    "    chain = prompt | llm | StrOutputParser()\n",
    "    generation = chain.invoke({\"question\": question, \"context\": contexts})\n",
    "    \n",
    "    print(\"생성된 답변 일부:\", generation[:200] + \"...\")\n",
    "    state[\"generation\"] = generation\n",
    "    return state\n",
    "\n",
    "# 2-5. Hallucination Check Node (환각 검사)\n",
    "@timing_decorator\n",
    "def hallucination_check_node(state: GraphState):\n",
    "    \"\"\"\n",
    "    생성된 답변에 환각(hallucination)이 있는지 검사합니다.\n",
    "    \"\"\"\n",
    "    print(\"--- 5. 환각 검사 시작 ---\")\n",
    "    contexts = state[\"retrieved_contexts\"]\n",
    "    generation = state[\"generation\"]\n",
    "    \n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "        \"\"\"당신은 AI 답변 검증 전문가입니다. 주어진 '참고 자료'를 바탕으로 '생성된 답변'이 만들어졌는지 확인해야 합니다.\n",
    "        '생성된 답변'의 모든 내용이 '참고 자료'에 근거하고 있다면 'yes'를, '참고 자료'에 없는 내용이 포함되어 있다면 'no'를 반환해주세요.\n",
    "\n",
    "        ## 참고 자료:\n",
    "        {context}\n",
    "\n",
    "        ## 생성된 답변:\n",
    "        {generation}\n",
    "\n",
    "        판단 (yes/no):\"\"\"\n",
    "    )\n",
    "    \n",
    "    chain = prompt | llm | StrOutputParser()\n",
    "    check_result = chain.invoke({\"context\": \"\\n\\n\".join(contexts), \"generation\": generation})\n",
    "\n",
    "    print(f\"환각 검사 결과: {check_result}\")\n",
    "    state[\"hallucination_check\"] = check_result.lower()\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af20e5c4",
   "metadata": {},
   "source": [
    "# Edge 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "30bccccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3-1. 질문 관련성 검사 후 분기\n",
    "def decide_after_relevance_check(state: GraphState):\n",
    "    \"\"\"\n",
    "    질문 관련성 검사 결과에 따라 다음 단계를 결정합니다.\n",
    "    - \"yes\": 질문 분해 단계로 이동\n",
    "    - \"no\": 종료\n",
    "    \"\"\"\n",
    "    if state[\"relevance_check\"] == \"yes\":\n",
    "        print(\"결과: 관련성 있음. 질문 분해를 진행합니다.\")\n",
    "        return \"decompose\"\n",
    "    else:\n",
    "        print(\"결과: 관련성 없음. 프로세스를 종료합니다.\")\n",
    "        return \"end\"\n",
    "\n",
    "# 3-2. 환각 검사 후 분기\n",
    "def decide_after_hallucination_check(state: GraphState):\n",
    "    \"\"\"\n",
    "    환각 검사 결과에 따라 다음 단계를 결정합니다.\n",
    "    - \"yes\": 환각 없음, 종료\n",
    "    - \"no\": 환각 존재, 답변 재생성\n",
    "    \"\"\"\n",
    "    if state[\"hallucination_check\"] == \"yes\":\n",
    "        print(\"결과: 환각 없음. 최종 답변을 반환합니다.\")\n",
    "        # print(state)\n",
    "        return \"end\"\n",
    "    else:\n",
    "        print(\"결과: 환각 존재. 답변을 다시 생성합니다.\")\n",
    "        return \"regenerate\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5d1668",
   "metadata": {},
   "source": [
    "# 그래프 통합\n",
    "\n",
    "## Naive RAG vs Graph RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "de444f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END, StateGraph\n",
    "\n",
    "# 그래프 빌더 생성\n",
    "def create_graph_rag():\n",
    "    graph_workflow = StateGraph(GraphState)\n",
    "\n",
    "    # 노드 추가\n",
    "    graph_workflow.add_node(\"relevance_check\", relevance_check_node)\n",
    "    graph_workflow.add_node(\"decompose_query\", decompose_query_node)\n",
    "    graph_workflow.add_node(\"retrieve\", retrieve_node)\n",
    "    graph_workflow.add_node(\"generate\", generate_node)\n",
    "    graph_workflow.add_node(\"hallucination_check\", hallucination_check_node)\n",
    "\n",
    "    # 엣지 연결\n",
    "    graph_workflow.set_entry_point(\"relevance_check\")\n",
    "    graph_workflow.add_conditional_edges(\n",
    "        \"relevance_check\",\n",
    "        decide_after_relevance_check,\n",
    "        {\"decompose\": \"decompose_query\", \"end\": END}\n",
    "    )\n",
    "    graph_workflow.add_edge(\"decompose_query\", \"retrieve\")\n",
    "    graph_workflow.add_edge(\"retrieve\", \"generate\")\n",
    "    graph_workflow.add_edge(\"generate\", \"hallucination_check\")\n",
    "    graph_workflow.add_conditional_edges(\n",
    "        \"hallucination_check\",\n",
    "        decide_after_hallucination_check,\n",
    "        {\"regenerate\": \"generate\", \"end\": END}\n",
    "    )\n",
    "\n",
    "    # 그래프 컴파일\n",
    "    return graph_workflow.compile()\n",
    "\n",
    "def create_meta_graph_rag():\n",
    "    graph_workflow = StateGraph(GraphState)\n",
    "\n",
    "    # 노드 추가\n",
    "    graph_workflow.add_node(\"relevance_check\", relevance_check_node)\n",
    "    graph_workflow.add_node(\"decompose_query\", decompose_query_node)\n",
    "    graph_workflow.add_node(\"retrieve\", meta_retrieve_node)\n",
    "    graph_workflow.add_node(\"generate\", generate_node)\n",
    "    graph_workflow.add_node(\"hallucination_check\", hallucination_check_node)\n",
    "\n",
    "    # 엣지 연결\n",
    "    graph_workflow.set_entry_point(\"relevance_check\")\n",
    "    graph_workflow.add_conditional_edges(\n",
    "        \"relevance_check\",\n",
    "        decide_after_relevance_check,\n",
    "        {\"decompose\": \"decompose_query\", \"end\": END}\n",
    "    )\n",
    "    graph_workflow.add_edge(\"decompose_query\", \"retrieve\")\n",
    "    graph_workflow.add_edge(\"retrieve\", \"generate\")\n",
    "    graph_workflow.add_edge(\"generate\", \"hallucination_check\")\n",
    "    graph_workflow.add_conditional_edges(\n",
    "        \"hallucination_check\",\n",
    "        decide_after_hallucination_check,\n",
    "        {\"regenerate\": \"generate\", \"end\": END}\n",
    "    )\n",
    "\n",
    "    # 그래프 컴파일\n",
    "    return graph_workflow.compile()\n",
    "\n",
    "def create_naive_rag():\n",
    "    naive_workflow = StateGraph(GraphState)\n",
    "    # 노드 추가\n",
    "    naive_workflow.add_node(\"decompose_query\", decompose_query_node)\n",
    "    naive_workflow.add_node(\"retrieve\", retrieve_node)\n",
    "    naive_workflow.add_node(\"generate\", generate_node)\n",
    "\n",
    "    # 엣지 연결\n",
    "    naive_workflow.set_entry_point(\"decompose_query\")\n",
    "    naive_workflow.add_edge(\"decompose_query\", \"retrieve\")\n",
    "    naive_workflow.add_edge(\"retrieve\", \"generate\")\n",
    "    naive_workflow.add_edge(\"generate\", END)\n",
    "    # 그래프 컴파일\n",
    "    return naive_workflow.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4069d161",
   "metadata": {},
   "source": [
    "# test 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b07e3708",
   "metadata": {},
   "outputs": [],
   "source": [
    "# app 생성\n",
    "graph_app = create_graph_rag()\n",
    "naive_app = create_naive_rag()\n",
    "graph_meta_app = create_meta_graph_rag()\n",
    "\n",
    "# HTP 그림 검사 예시 질문\n",
    "inputs = {\n",
    "    \"original_question\": \"집에 창문은 2개 존재하고 크기는 적절함. 문은 집의 크기에 비해 작으며 문과 바깥이 길로 이어져 있지 않음.\",\n",
    "    \"category\": \"집\",\n",
    "}\n",
    "\n",
    "interupt_inputs = {\n",
    "    \"original_question\": \"오늘의 날씨는? 대한민국의 수도는? 최근 야구 경기 결과는?\",\n",
    "    \"category\": \"집\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e8a834",
   "metadata": {},
   "source": [
    "# Naive RAG time check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e10160d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 2. 질문 분해 시작 ---\n",
      "분해된 질문: ['오늘의 날씨에 대한 질문이 있다.', '대한민국의 수도에 대한 질문이 있다.', '최근 야구 경기 결과에 대한 질문이 있다.']\n",
      "Execution time for decompose_query_node: 1.20 seconds\n",
      "--- 3. 정보 검색 시작 (카테고리: 집) ---\n",
      "  - 검색 쿼리: '오늘의 날씨에 대한 질문이 있다.'\n",
      "  - 검색 쿼리: '대한민국의 수도에 대한 질문이 있다.'\n",
      "  - 검색 쿼리: '최근 야구 경기 결과에 대한 질문이 있다.'\n",
      "검색된 해석 Context 수: 11\n",
      "Execution time for retrieve_node: 1.17 seconds\n",
      "--- 4. 답변 생성 시작 ---\n",
      "생성된 답변 일부: ## 최종 해석 보고서\n",
      "\n",
      "본 보고서는 내담자의 HTP 그림 심리검사 결과를 토대로 심리상태를 종합적으로 분석한 내용입니다. 상담사가 관찰한 그림 특징을  해석 참고자료에 기반하여 논리적으로 연결하여 설명하겠습니다.\n",
      "\n",
      "### 1. 그림 크기\n",
      "내담자가 그림을 지나치게 작게 그렸다면, 이는 내면에 열등감이나 부적절감을 느끼고 있다는 가능성을 제시합니다. 이는 자...\n",
      "Execution time for generate_node: 21.84 seconds\n",
      "--- Individual Node Execution Times ---\n",
      "- decompose_query_node: 1.1987 seconds\n",
      "- retrieve_node: 1.1719 seconds\n",
      "- generate_node: 21.8375 seconds\n",
      "\n",
      "-----------------------------------------\n",
      "Total execution time (sum of nodes): 24.2081 seconds\n"
     ]
    }
   ],
   "source": [
    "# 시간 초기화\n",
    "execution_times = {}\n",
    "# 노드수행\n",
    "config = {\n",
    "    \"configurable\": {\n",
    "        \"faiss_store\": faiss_store, # 초기화 단계에서 생성한 faiss_store 객체\n",
    "        \"bm25_retriever_cache\": bm25_retriever_cache # 초기화 단계에서 생성한 bm25_retriever_cache 객체\n",
    "    }\n",
    "}\n",
    "naive_app.invoke(interupt_inputs, config=config)\n",
    "\n",
    "# --- 최종 결과 분석 ---\n",
    "print(\"--- Individual Node Execution Times ---\")\n",
    "for node_name, duration in execution_times.items():\n",
    "    print(f\"- {node_name}: {duration:.4f} seconds\")\n",
    "\n",
    "total_time = sum(execution_times.values())\n",
    "print(\"\\n-----------------------------------------\")\n",
    "print(f\"Total execution time (sum of nodes): {total_time:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c510ae",
   "metadata": {},
   "source": [
    "# Graph RAG time check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2434d42a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1. 질문 관련성 검사 시작 ---\n",
      "질문 관련성: yes\n",
      "Execution time for relevance_check_node: 0.70 seconds\n",
      "결과: 관련성 있음. 질문 분해를 진행합니다.\n",
      "--- 2. 질문 분해 시작 ---\n",
      "분해된 질문: ['집 창문의 개수는 2개이고 크기는 적절하다.', '집 문의 크기가 집 전체에 비해 작다.', '집과 외부를 잇는 길이 그려져 있지 않다.']\n",
      "Execution time for decompose_query_node: 1.76 seconds\n",
      "--- 3. 정보 검색 시작 ---\n",
      "  - 검색 쿼리: '집 창문의 개수는 2개이고 크기는 적절하다.'\n",
      "  - 검색 쿼리: '집 문의 크기가 집 전체에 비해 작다.'\n",
      "  - 검색 쿼리: '집과 외부를 잇는 길이 그려져 있지 않다.'\n",
      "검색된 해석 Context 수: 12\n",
      "Execution time for retrieve_node: 1.08 seconds\n",
      "--- 4. 답변 생성 시작 ---\n",
      "생성된 답변 일부: ## 상담사의 그림 특징 관찰 내용:\n",
      "집에 창문은 2개 존재하고 크기는 적절함. 문은 집의 크기에 비해 작으며 문과 바깥이 길로 이어져 있지 않음.\n",
      "\n",
      "## 최종 해석 보고서:\n",
      "\n",
      "### 주요 특징 및 해석적 가설\n",
      "입력해주신 그림의 묘사를 바탕으로, 주요 구조적 특징에 대한 심리적 의미를 아래와 같이 분석할 수 있습니다.\n",
      "\n",
      "#### 특징 1: 창문 두 개와 적...\n",
      "Execution time for generate_node: 10.91 seconds\n",
      "--- 5. 환각 검사 시작 ---\n",
      "환각 검사 결과: yes\n",
      "Execution time for hallucination_check_node: 0.82 seconds\n",
      "결과: 환각 없음. 최종 답변을 반환합니다.\n",
      "--- Individual Node Execution Times ---\n",
      "- relevance_check_node: 0.6982 seconds\n",
      "- decompose_query_node: 1.7647 seconds\n",
      "- retrieve_node: 1.0848 seconds\n",
      "- generate_node: 10.9078 seconds\n",
      "- hallucination_check_node: 0.8174 seconds\n",
      "\n",
      "-----------------------------------------\n",
      "Total execution time (sum of nodes): 15.2728 seconds\n",
      "\n",
      "--- Graph RAG Result ---\n",
      "Graph RAG Generation: ## 상담사의 그림 특징 관찰 내용:\n",
      "집에 창문은 2개 존재하고 크기는 적절함. 문은 집의 크기에 비해 작으며 문과 바깥이 길로 이어져 있지 않음.\n",
      "\n",
      "## 최종 해석 보고서:\n",
      "\n",
      "### 주요 특징 및 해석적 가설\n",
      "입력해주신 그림의 묘사를 바탕으로, 주요 구조적 특징에 대한 심리적 의미를 아래와 같이 분석할 수 있습니다.\n",
      "\n",
      "#### 특징 1: 창문 두 개와 적절한 크기\n",
      "창문이 2개이며 그 크기가 적절한 것은 대인관계에 대한 일정 수준의 개방성과 환경과의 접촉 정도를 나타냅니다. 두 개의 창문은 다양한 시각으로 세상을 바라보고자 하는 의지를 시사합니다. 이는 외부 세계에 대한 호기심이나 이해를 원한다는 긍정적인 신호로 해석할 수 있습니다. 그러나 창문이 집의 다른 구조물에 비해 상대적으로 크지 않기 때문에, 지나치게 개방적이지 않으며, 적절한 거리 유지를 원하고 있다는 점에서 스스로를 보호하고자 하는 심리를 엿볼 수 있습니다.\n",
      "\n",
      "#### 특징 2: 문이 작고 외부와 연결되지 않음\n",
      "문이 집의 크기에 비해 작고 외부와 길이 이어져 있지 않은 점은 대인관계나 외부 세계에 대한 접근성의 제약을 나타냅니다. 이는 내담자가 인간관계에서 느끼는 장애감이나, 타인과의 연결에 대한 불안감을 암시합니다. 문이 소극적이고 작은 것은 대인관계에서의 무력감을 나타내며, 그로 인해 현실로부터의 도피의 경향이 있을 수 있습니다. 이러한 무력감은 관계 형성에 대한 두려움이나 불편감과 긴밀하게 연결될 수 있습니다.\n",
      "\n",
      "### 종합 소견\n",
      "종합적으로 볼 때, 창문의 적절한 크기와 개수를 가진 것과 문이 작고 외부와 연결되지 않은 점이 서로 연결되어, 외부 세계와의 관계에서 위축감과 불안감을 반영할 가능성을 보여줍니다. 이는 내담자가 대인관계에서의 편안함을 느끼지 못하고 있으며, 현실과의 접촉이 제한적일 수 있음을 암시합니다. 이러한 심리적 특징은 대인관계의 형성이 어려움으로 이어질 수 있으며, 나아가 사회적 고립감이나 불안정한 감정을 야기할 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "# 시간 초기화\n",
    "execution_times = {}\n",
    "# 노드수행\n",
    "config = {\n",
    "    \"configurable\": {\n",
    "        \"faiss_store\": faiss_store, # 초기화 단계에서 생성한 faiss_store 객체\n",
    "        \"bm25_retriever_cache\": bm25_retriever_cache # 초기화 단계에서 생성한 bm25_retriever_cache 객체\n",
    "    }\n",
    "}\n",
    "graph_result = graph_app.invoke(inputs, config=config)\n",
    "\n",
    "# --- 최종 결과 분석 ---\n",
    "print(\"--- Individual Node Execution Times ---\")\n",
    "for node_name, duration in execution_times.items():\n",
    "    print(f\"- {node_name}: {duration:.4f} seconds\")\n",
    "\n",
    "total_time = sum(execution_times.values())\n",
    "print(\"\\n-----------------------------------------\")\n",
    "print(f\"Total execution time (sum of nodes): {total_time:.4f} seconds\")\n",
    "\n",
    "print(\"\\n--- Graph RAG Result ---\")\n",
    "print(f\"Graph RAG Generation: {graph_result['generation']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adaa6913",
   "metadata": {},
   "source": [
    "# Meta Graph RAG time check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2c20ab37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1. 질문 관련성 검사 시작 ---\n",
      "질문 관련성: yes\n",
      "Execution time for relevance_check_node: 0.62 seconds\n",
      "결과: 관련성 있음. 질문 분해를 진행합니다.\n",
      "--- 2. 질문 분해 시작 ---\n",
      "분해된 질문: ['집 창문의 개수는 2개이고 크기는 적절하다.', '집 문의 크기가 집 전체에 비해 작다.', '집과 외부를 잇는 길이 그려져 있지 않다.']\n",
      "Execution time for decompose_query_node: 1.74 seconds\n",
      "--- 3. 정보 검색 시작 ---\n",
      "  - 검색 쿼리: '집 창문의 개수는 2개이고 크기는 적절하다.'\n",
      "  - 검색 쿼리: '집 문의 크기가 집 전체에 비해 작다.'\n",
      "  - 검색 쿼리: '집과 외부를 잇는 길이 그려져 있지 않다.'\n",
      "검색된 해석 Context 수: 12\n",
      "Execution time for retrieve_node: 1.58 seconds\n",
      "--- 4. 답변 생성 시작 ---\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"Input to ChatPromptTemplate is missing variables {'category'}.  Expected: ['category', 'context', 'question'] Received: ['question', 'context']\\nNote: if you intended {category} to be part of the string and not a variable, please escape it with double curly braces like: '{{category}}'.\\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT \"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      3\u001b[39m config = {\n\u001b[32m      4\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mconfigurable\u001b[39m\u001b[33m\"\u001b[39m: {\n\u001b[32m      5\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mfaiss_store\u001b[39m\u001b[33m\"\u001b[39m: faiss_store, \u001b[38;5;66;03m# 초기화 단계에서 생성한 faiss_store 객체\u001b[39;00m\n\u001b[32m      6\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mbm25_retriever_cache\u001b[39m\u001b[33m\"\u001b[39m: bm25_retriever_cache \u001b[38;5;66;03m# 초기화 단계에서 생성한 bm25_retriever_cache 객체\u001b[39;00m\n\u001b[32m      7\u001b[39m     }\n\u001b[32m      8\u001b[39m }\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# 노드수행\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m meta_graph_result = \u001b[43mgraph_app\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# --- 최종 결과 분석 ---\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m--- Individual Node Execution Times ---\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\P\\Desktop\\rag_embed\\first_pjt\\venv\\Lib\\site-packages\\langgraph\\pregel\\main.py:3015\u001b[39m, in \u001b[36mPregel.invoke\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, **kwargs)\u001b[39m\n\u001b[32m   3012\u001b[39m chunks: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] | Any] = []\n\u001b[32m   3013\u001b[39m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] = []\n\u001b[32m-> \u001b[39m\u001b[32m3015\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3016\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3017\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3018\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3019\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mupdates\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m   3020\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m   3021\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3022\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3023\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3024\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3025\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3026\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3027\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3028\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   3029\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m   3030\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\P\\Desktop\\rag_embed\\first_pjt\\venv\\Lib\\site-packages\\langgraph\\pregel\\main.py:2642\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[39m\n\u001b[32m   2640\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop.match_cached_writes():\n\u001b[32m   2641\u001b[39m     loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2642\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2643\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrites\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2644\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2645\u001b[39m \u001b[43m    \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2646\u001b[39m \u001b[43m    \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43maccept_push\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2647\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2648\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2649\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_output\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2650\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubgraphs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqueue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEmpty\u001b[49m\n\u001b[32m   2651\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2652\u001b[39m loop.after_tick()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\P\\Desktop\\rag_embed\\first_pjt\\venv\\Lib\\site-packages\\langgraph\\pregel\\_runner.py:162\u001b[39m, in \u001b[36mPregelRunner.tick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[39m\n\u001b[32m    160\u001b[39m t = tasks[\u001b[32m0\u001b[39m]\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m162\u001b[39m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    166\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    167\u001b[39m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m                \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    176\u001b[39m     \u001b[38;5;28mself\u001b[39m.commit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    177\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\P\\Desktop\\rag_embed\\first_pjt\\venv\\Lib\\site-packages\\langgraph\\pregel\\_retry.py:42\u001b[39m, in \u001b[36mrun_with_retry\u001b[39m\u001b[34m(task, retry_policy, configurable)\u001b[39m\n\u001b[32m     40\u001b[39m     task.writes.clear()\n\u001b[32m     41\u001b[39m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     44\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\P\\Desktop\\rag_embed\\first_pjt\\venv\\Lib\\site-packages\\langgraph\\_internal\\_runnable.py:657\u001b[39m, in \u001b[36mRunnableSeq.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    655\u001b[39m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[32m    656\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m657\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    658\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    659\u001b[39m     \u001b[38;5;28minput\u001b[39m = step.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\P\\Desktop\\rag_embed\\first_pjt\\venv\\Lib\\site-packages\\langgraph\\_internal\\_runnable.py:401\u001b[39m, in \u001b[36mRunnableCallable.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    399\u001b[39m         run_manager.on_chain_end(ret)\n\u001b[32m    400\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m     ret = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[32m    403\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ret.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 13\u001b[39m, in \u001b[36mtiming_decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(*args, **kwargs):\n\u001b[32m     12\u001b[39m     start_time = time.time()\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m     end_time = time.time()\n\u001b[32m     15\u001b[39m     elapsed_time = end_time - start_time\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 191\u001b[39m, in \u001b[36mgenerate_node\u001b[39m\u001b[34m(state)\u001b[39m\n\u001b[32m    139\u001b[39m prompt = ChatPromptTemplate.from_template(\n\u001b[32m    140\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"당신은 HTP 그림 심리검사 결과 해석 전문가입니다.\u001b[39;00m\n\u001b[32m    141\u001b[39m \u001b[33;03m    상담사가 관찰한 '그림 특징'과 그에 대한 '해석 참고자료'가 주어집니다. \u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    187\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m    188\u001b[39m )\n\u001b[32m    190\u001b[39m chain = prompt | llm | StrOutputParser()\n\u001b[32m--> \u001b[39m\u001b[32m191\u001b[39m generation = \u001b[43mchain\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mquestion\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontext\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontexts\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    193\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m생성된 답변 일부:\u001b[39m\u001b[33m\"\u001b[39m, generation[:\u001b[32m200\u001b[39m] + \u001b[33m\"\u001b[39m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    194\u001b[39m state[\u001b[33m\"\u001b[39m\u001b[33mgeneration\u001b[39m\u001b[33m\"\u001b[39m] = generation\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\P\\Desktop\\rag_embed\\first_pjt\\venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3044\u001b[39m, in \u001b[36mRunnableSequence.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3042\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m   3043\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m i == \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m3044\u001b[39m         input_ = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3045\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   3046\u001b[39m         input_ = context.run(step.invoke, input_, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\P\\Desktop\\rag_embed\\first_pjt\\venv\\Lib\\site-packages\\langchain_core\\prompts\\base.py:216\u001b[39m, in \u001b[36mBasePromptTemplate.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.tags:\n\u001b[32m    215\u001b[39m     config[\u001b[33m\"\u001b[39m\u001b[33mtags\u001b[39m\u001b[33m\"\u001b[39m] = config[\u001b[33m\"\u001b[39m\u001b[33mtags\u001b[39m\u001b[33m\"\u001b[39m] + \u001b[38;5;28mself\u001b[39m.tags\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_with_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_format_prompt_with_error_handling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    220\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrun_type\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    221\u001b[39m \u001b[43m    \u001b[49m\u001b[43mserialized\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_serialized\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    222\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\P\\Desktop\\rag_embed\\first_pjt\\venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:1939\u001b[39m, in \u001b[36mRunnable._call_with_config\u001b[39m\u001b[34m(self, func, input_, config, run_type, serialized, **kwargs)\u001b[39m\n\u001b[32m   1935\u001b[39m     child_config = patch_config(config, callbacks=run_manager.get_child())\n\u001b[32m   1936\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(child_config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m   1937\u001b[39m         output = cast(\n\u001b[32m   1938\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mOutput\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m-> \u001b[39m\u001b[32m1939\u001b[39m             \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1940\u001b[39m \u001b[43m                \u001b[49m\u001b[43mcall_func_with_variable_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m   1941\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1942\u001b[39m \u001b[43m                \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1943\u001b[39m \u001b[43m                \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1944\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1945\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1946\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m   1947\u001b[39m         )\n\u001b[32m   1948\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1949\u001b[39m     run_manager.on_chain_error(e)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\P\\Desktop\\rag_embed\\first_pjt\\venv\\Lib\\site-packages\\langchain_core\\runnables\\config.py:429\u001b[39m, in \u001b[36mcall_func_with_variable_args\u001b[39m\u001b[34m(func, input, config, run_manager, **kwargs)\u001b[39m\n\u001b[32m    427\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[32m    428\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m] = run_manager\n\u001b[32m--> \u001b[39m\u001b[32m429\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\P\\Desktop\\rag_embed\\first_pjt\\venv\\Lib\\site-packages\\langchain_core\\prompts\\base.py:189\u001b[39m, in \u001b[36mBasePromptTemplate._format_prompt_with_error_handling\u001b[39m\u001b[34m(self, inner_input)\u001b[39m\n\u001b[32m    188\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_format_prompt_with_error_handling\u001b[39m(\u001b[38;5;28mself\u001b[39m, inner_input: \u001b[38;5;28mdict\u001b[39m) -> PromptValue:\n\u001b[32m--> \u001b[39m\u001b[32m189\u001b[39m     inner_input_ = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43minner_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    190\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.format_prompt(**inner_input_)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\P\\Desktop\\rag_embed\\first_pjt\\venv\\Lib\\site-packages\\langchain_core\\prompts\\base.py:183\u001b[39m, in \u001b[36mBasePromptTemplate._validate_input\u001b[39m\u001b[34m(self, inner_input)\u001b[39m\n\u001b[32m    177\u001b[39m     example_key = missing.pop()\n\u001b[32m    178\u001b[39m     msg += (\n\u001b[32m    179\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mNote: if you intended \u001b[39m\u001b[38;5;130;01m{{\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mexample_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m}}\u001b[39;00m\u001b[33m to be part of the string\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    180\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m and not a variable, please escape it with double curly braces like: \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    181\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;130;01m{{\u001b[39;00m\u001b[38;5;130;01m{{\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mexample_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m}}\u001b[39;00m\u001b[38;5;130;01m}}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    182\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m183\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\n\u001b[32m    184\u001b[39m         create_message(message=msg, error_code=ErrorCode.INVALID_PROMPT_INPUT)\n\u001b[32m    185\u001b[39m     )\n\u001b[32m    186\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m inner_input\n",
      "\u001b[31mKeyError\u001b[39m: \"Input to ChatPromptTemplate is missing variables {'category'}.  Expected: ['category', 'context', 'question'] Received: ['question', 'context']\\nNote: if you intended {category} to be part of the string and not a variable, please escape it with double curly braces like: '{{category}}'.\\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT \"",
      "During task with name 'generate' and id 'bb6714ec-ed0f-5b8e-3607-987ac2c5f3ce'"
     ]
    }
   ],
   "source": [
    "# 시간 초기화\n",
    "execution_times = {}\n",
    "config = {\n",
    "    \"configurable\": {\n",
    "        \"faiss_store\": faiss_store, # 초기화 단계에서 생성한 faiss_store 객체\n",
    "        \"bm25_retriever_cache\": bm25_retriever_cache # 초기화 단계에서 생성한 bm25_retriever_cache 객체\n",
    "    }\n",
    "}\n",
    "# 노드수행\n",
    "\n",
    "meta_graph_result = graph_app.invoke(inputs, config=config)\n",
    "\n",
    "# --- 최종 결과 분석 ---\n",
    "print(\"--- Individual Node Execution Times ---\")\n",
    "for node_name, duration in execution_times.items():\n",
    "    print(f\"- {node_name}: {duration:.4f} seconds\")\n",
    "\n",
    "total_time = sum(execution_times.values())\n",
    "print(\"\\n-----------------------------------------\")\n",
    "print(f\"Total execution time (sum of nodes): {total_time:.4f} seconds\")\n",
    "\n",
    "print(\"\\n--- Graph RAG Result ---\")\n",
    "print(f\"Graph RAG Generation: {graph_result['generation']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce42b99",
   "metadata": {},
   "source": [
    "# LLM as a judge\n",
    "평가자 gpt-4o\n",
    "[https://galtea.ai/2025/05/02/evaluation-of-judges.html]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9f66f821",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "judge_llm = ChatOpenAI(model=\"gpt-4o\", temperature=0.0)\n",
    "\n",
    "\n",
    "class JudgeOutput(BaseModel):\n",
    "    \"\"\"\n",
    "    LLM 평가 결과를 저장하는 모델\n",
    "    \"\"\"\n",
    "\n",
    "    better_answer: str = Field(description=\"더 우수한 답변 (A 또는 B)\")\n",
    "    evaluation_reason: str = Field(description=\"평가 사유 및 비교 분석 근거\")\n",
    "\n",
    "\n",
    "# 1. 평가 프롬프트 템플릿 정의\n",
    "judge_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    당신은 심리검사 해석 전문가이자 평가자입니다.\n",
    "    그림 심리 해석에 대한 결과를 보고 비교 평가를 진행해야 합니다. 질문은 그림에 대한 관찰 묘사의 종합 쿼리입니다. 해당 question을 분해하여 각 쿼리에 대한 질문을 검색하고 RAG를 통해 해석합니다.\n",
    "    아래 두 개의 답변(A, B)은 동일한 질문에 대해 서로 다른 RAG 파이프라인에서 생성된 결과입니다.\n",
    "    - 답변은 무작위 적으로 응답된다.\n",
    "    - 어떤 시스템에서 생성되었는지 고려하지 말고, 오직 답변의 품질만을 기준으로 공정하게 평가하라.\n",
    "    - 각 항목에 대해 점수를 부여하고, 최종 점수를 기준으로 winner를 선정하라 \n",
    "    평가 기준:\n",
    "    정확성: 사실에 기반한 정확한 정보인지\n",
    "    관련성: 질문에 적절히 답변하는지\n",
    "    일관성: 논리적이고 모순 없는 답변인지\n",
    "    유용성: 실질적으로 도움이 되는 답변인지\n",
    "\n",
    "    - 질문: {question}\n",
    "    - 답변 A : {answer_a}\n",
    "    - 답변 B : {answer_b}\n",
    "\n",
    "    두 답변을 비교하여 다음 기준에 따라 평가하세요:\n",
    "    1. 해석의 전문성 및 신뢰성\n",
    "    2. 질문과의 관련성\n",
    "    3. 환각(hallucination) 여부\n",
    "    4. 답변의 풍부함과 논리적 연결성\n",
    "\n",
    "    아래 형식으로 평가 결과를 작성하세요:\n",
    "    {{\n",
    "        \"better_answer\": \"A\" or \"B\",  # 더 우수한 답변\n",
    "        \"evaluation_reason\": \"이유 및 비교 분석\"  # 평가 사유 및 비교 분석 근거\n",
    "    }}\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# 2. 평가 체인 생성 (LLM + 프롬프트 + 출력 파서)\n",
    "judge_chain = judge_prompt | judge_llm | JsonOutputParser(pydantic_object=JudgeOutput)\n",
    "\n",
    "# 3. 평가 함수 정의\n",
    "def evaluate_rag_outputs(question, result_A, result_B):\n",
    "    \"\"\"\n",
    "    두 RAG 파이프라인의 결과를 LLM 평가자에게 비교 평가받는 함수\n",
    "    \"\"\"\n",
    "\n",
    "    # 평가자에게 입력 전달\n",
    "    judge_result = judge_chain.invoke(\n",
    "        {\n",
    "            \"question\": question,\n",
    "            \"answer_a\": result_A[\"generation\"],  # Graph RAG의 최종 답변\n",
    "            \"answer_b\": result_B[\"generation\"],  # Meta Graph RAG의 최종 답변\n",
    "        }\n",
    "    )\n",
    "    return judge_result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0e140e37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1. 질문 관련성 검사 시작 ---\n",
      "질문 관련성: yes\n",
      "Execution time for relevance_check_node: 0.69 seconds\n",
      "결과: 관련성 있음. 질문 분해를 진행합니다.\n",
      "--- 2. 질문 분해 시작 ---\n",
      "분해된 질문: ['집은 종이의 왼쪽 하단 구석에 치우쳐 그려져 있다.', '문의 크기는 매우 작다.', '문은 자물쇠로 잠겨 있다.', '창문에는 커튼이 쳐져 있어 안이 보이지 않는다.', '전체적으로 선의 필압이 매우 약하다.', '그림의 선이 흐리게 표현되어 있다.']\n",
      "Execution time for decompose_query_node: 2.61 seconds\n",
      "--- 3. 정보 검색 시작 ---\n",
      "  - 검색 쿼리: '집은 종이의 왼쪽 하단 구석에 치우쳐 그려져 있다.'\n",
      "  - 검색 쿼리: '문의 크기는 매우 작다.'\n",
      "  - 검색 쿼리: '문은 자물쇠로 잠겨 있다.'\n",
      "  - 검색 쿼리: '창문에는 커튼이 쳐져 있어 안이 보이지 않는다.'\n",
      "  - 검색 쿼리: '전체적으로 선의 필압이 매우 약하다.'\n",
      "  - 검색 쿼리: '그림의 선이 흐리게 표현되어 있다.'\n",
      "검색된 해석 Context 수: 28\n",
      "Execution time for retrieve_node: 3.40 seconds\n",
      "--- 4. 답변 생성 시작 ---\n",
      "생성된 답변 일부: # HTP 그림 심리검사 해석 보고서\n",
      "\n",
      "## 내담자 심리상태 종합 해석\n",
      "\n",
      "본 보고서는 내담자가 그린 HTP 그림을 바탕으로 심리 상태를 해석한 결과입니다. 특히 집의 위치, 문과 창문 처리, 선의 필압 및 상태 등을 중점적으로 분석하였습니다.\n",
      "\n",
      "### 1. 집의 위치 및 구조\n",
      "내담자는 집을 종이의 왼쪽 하단 구석에 그렸습니다. 이는 내담자의 우울감이나 위축...\n",
      "Execution time for generate_node: 14.33 seconds\n",
      "--- 5. 환각 검사 시작 ---\n",
      "환각 검사 결과: yes\n",
      "Execution time for hallucination_check_node: 0.79 seconds\n",
      "결과: 환각 없음. 최종 답변을 반환합니다.\n",
      "--- 1. 질문 관련성 검사 시작 ---\n",
      "질문 관련성: yes\n",
      "Execution time for relevance_check_node: 0.53 seconds\n",
      "결과: 관련성 있음. 질문 분해를 진행합니다.\n",
      "--- 2. 질문 분해 시작 ---\n",
      "분해된 질문: ['집은 종이의 왼쪽 하단 구석에 치우쳐 그려져 있다.', '집 문의 크기가 매우 작고 자물쇠로 잠겨 있다.', '창문에는 커튼이 쳐져 있어 내부가 보이지 않는다.', '전체적으로 선의 필압이 매우 약하고 흐리다.']\n",
      "Execution time for decompose_query_node: 2.34 seconds\n",
      "--- 3. 정보 검색 시작 (카테고리: 집) ---\n",
      "  - 검색 쿼리: '집은 종이의 왼쪽 하단 구석에 치우쳐 그려져 있다.'\n",
      "  - 검색 쿼리: '집 문의 크기가 매우 작고 자물쇠로 잠겨 있다.'\n",
      "  - 검색 쿼리: '창문에는 커튼이 쳐져 있어 내부가 보이지 않는다.'\n",
      "  - 검색 쿼리: '전체적으로 선의 필압이 매우 약하고 흐리다.'\n",
      "검색된 해석 Context 수: 17\n",
      "Execution time for meta_retrieve_node: 1.44 seconds\n",
      "--- 4. 답변 생성 시작 ---\n",
      "생성된 답변 일부: ### 최종 해석 보고서\n",
      "\n",
      "#### 상담사의 관찰 내용 요약\n",
      "내담자는 집을 종이의 왼쪽 하단 구석에 치우쳐 그렸으며, 문은 매우 작고 자물쇠로 잠겨 있습니다. 창문에는 커튼이 쳐져 있어 내부가 보이지 않고, 전체적으로 선의 필압이 매우 약하고 흐릿한 특징을 보였습니다.\n",
      "\n",
      "#### 1. 집의 위치 및 구성 요소\n",
      "내담자가 집을 그림의 왼쪽 하단 구석에 배치한 ...\n",
      "Execution time for generate_node: 14.27 seconds\n",
      "--- 5. 환각 검사 시작 ---\n",
      "환각 검사 결과: yes\n",
      "Execution time for hallucination_check_node: 0.56 seconds\n",
      "결과: 환각 없음. 최종 답변을 반환합니다.\n",
      "--- 1. 질문 관련성 검사 시작 ---\n",
      "질문 관련성: yes\n",
      "Execution time for relevance_check_node: 0.46 seconds\n",
      "결과: 관련성 있음. 질문 분해를 진행합니다.\n",
      "--- 2. 질문 분해 시작 ---\n",
      "분해된 질문: ['지붕의 크기가 집에 비해 과도하게 크다.', '벽은 벽돌 무늬로 세밀하게 묘사되어있다.', '문이 그려져 있지 않다.', '굴뚝에서 연기가 많이 피어오르고 있다.']\n",
      "Execution time for decompose_query_node: 2.03 seconds\n",
      "--- 3. 정보 검색 시작 ---\n",
      "  - 검색 쿼리: '지붕의 크기가 집에 비해 과도하게 크다.'\n",
      "  - 검색 쿼리: '벽은 벽돌 무늬로 세밀하게 묘사되어있다.'\n",
      "  - 검색 쿼리: '문이 그려져 있지 않다.'\n",
      "  - 검색 쿼리: '굴뚝에서 연기가 많이 피어오르고 있다.'\n",
      "검색된 해석 Context 수: 15\n",
      "Execution time for retrieve_node: 1.83 seconds\n",
      "--- 4. 답변 생성 시작 ---\n",
      "생성된 답변 일부: **최종 해석 보고서**\n",
      "\n",
      "본 그림 검사에서 나타난 여러 특징을 바탕으로 내담자의 심리상태를 다음과 같이 해석할 수 있습니다.\n",
      "\n",
      "1. **지붕의 과도한 크기**: 지붕이 집에 비해 지나치게 크다는 점은 내담자가 공상적 사고나 과도한 상상력에서 많은 시간을 보내고 있음을 의미합니다. 이는 내담자가 현실과의 접촉을 회피하며 내적인 공상에 몰두하고 있다는 신호일...\n",
      "Execution time for generate_node: 12.11 seconds\n",
      "--- 5. 환각 검사 시작 ---\n",
      "환각 검사 결과: yes\n",
      "Execution time for hallucination_check_node: 0.46 seconds\n",
      "결과: 환각 없음. 최종 답변을 반환합니다.\n",
      "--- 1. 질문 관련성 검사 시작 ---\n",
      "질문 관련성: yes\n",
      "Execution time for relevance_check_node: 0.95 seconds\n",
      "결과: 관련성 있음. 질문 분해를 진행합니다.\n",
      "--- 2. 질문 분해 시작 ---\n",
      "분해된 질문: ['집의 지붕이 집에 비해 과도하게 크다.', '집의 벽은 벽돌 무늬로 세밀하게 묘사되어 있다.', '집에는 문이 그려져 있지 않다.', '굴뚝에서는 연기가 많이 피어오르고 있다.']\n",
      "Execution time for decompose_query_node: 1.92 seconds\n",
      "--- 3. 정보 검색 시작 (카테고리: 집) ---\n",
      "  - 검색 쿼리: '집의 지붕이 집에 비해 과도하게 크다.'\n",
      "  - 검색 쿼리: '집의 벽은 벽돌 무늬로 세밀하게 묘사되어 있다.'\n",
      "  - 검색 쿼리: '집에는 문이 그려져 있지 않다.'\n",
      "  - 검색 쿼리: '굴뚝에서는 연기가 많이 피어오르고 있다.'\n",
      "검색된 해석 Context 수: 15\n",
      "Execution time for meta_retrieve_node: 1.98 seconds\n",
      "--- 4. 답변 생성 시작 ---\n",
      "생성된 답변 일부: ### 최종 해석 보고서\n",
      "\n",
      "본 보고서는 상담사가 제공한 그림 특징 관찰 내용과 해석 참고자료를 바탕으로 내담자의 심리상태를 분석한 것입니다. 내담자의 그림에서 주목할 만한 요소는 지붕이 과도하게 크고, 벽은 세밀하게 묘사된 점, 문이 그려지지 않았으며 굴뚝에서 연기가 많이 피어오르고 있다는 점입니다. 이러한 요소들은 내담자의 심리적 상태에 대해 다음과 같이...\n",
      "Execution time for generate_node: 15.86 seconds\n",
      "--- 5. 환각 검사 시작 ---\n",
      "환각 검사 결과: yes\n",
      "Execution time for hallucination_check_node: 0.65 seconds\n",
      "결과: 환각 없음. 최종 답변을 반환합니다.\n",
      "--- 1. 질문 관련성 검사 시작 ---\n",
      "질문 관련성: yes\n",
      "Execution time for relevance_check_node: 0.78 seconds\n",
      "결과: 관련성 있음. 질문 분해를 진행합니다.\n",
      "--- 2. 질문 분해 시작 ---\n",
      "분해된 질문: ['집은 조감도 시점으로 그려져 있다.', '집의 벽이 투명하여 내부가 보인다.', '집으로 향하는 길이 그려져 있지 않다.']\n",
      "Execution time for decompose_query_node: 1.63 seconds\n",
      "--- 3. 정보 검색 시작 ---\n",
      "  - 검색 쿼리: '집은 조감도 시점으로 그려져 있다.'\n",
      "  - 검색 쿼리: '집의 벽이 투명하여 내부가 보인다.'\n",
      "  - 검색 쿼리: '집으로 향하는 길이 그려져 있지 않다.'\n",
      "검색된 해석 Context 수: 9\n",
      "Execution time for retrieve_node: 1.09 seconds\n",
      "--- 4. 답변 생성 시작 ---\n",
      "생성된 답변 일부: ### 최종 해석 보고서\n",
      "\n",
      "#### 1. 그림의 형태 및 시점\n",
      "내담자가 그린 집 그림은 조감도 시점으로 그려졌으며, 벽이 투명하여 내부가 보이는 형태를 취하고 있습니다. 이러한 그림의 시점은 현재 가정 상황에 대한 불만족이나, 벗어나고 싶은 심리를 암시합니다. 이는 전통적인 가족 가치관에 대한 반감이 반영된 것일 수 있으며, 내담자가 내면적으로 가족관계에서...\n",
      "Execution time for generate_node: 11.71 seconds\n",
      "--- 5. 환각 검사 시작 ---\n",
      "환각 검사 결과: yes\n",
      "Execution time for hallucination_check_node: 0.44 seconds\n",
      "결과: 환각 없음. 최종 답변을 반환합니다.\n",
      "--- 1. 질문 관련성 검사 시작 ---\n",
      "질문 관련성: yes\n",
      "Execution time for relevance_check_node: 0.41 seconds\n",
      "결과: 관련성 있음. 질문 분해를 진행합니다.\n",
      "--- 2. 질문 분해 시작 ---\n",
      "분해된 질문: ['집은 조감도 시점에서 그려져 있다.', '집의 벽은 투명하게 표현되어 내부가 보인다.', '집으로 향하는 길이 그려져 있지 않다.']\n",
      "Execution time for decompose_query_node: 1.54 seconds\n",
      "--- 3. 정보 검색 시작 (카테고리: 집) ---\n",
      "  - 검색 쿼리: '집은 조감도 시점에서 그려져 있다.'\n",
      "  - 검색 쿼리: '집의 벽은 투명하게 표현되어 내부가 보인다.'\n",
      "  - 검색 쿼리: '집으로 향하는 길이 그려져 있지 않다.'\n",
      "검색된 해석 Context 수: 8\n",
      "Execution time for meta_retrieve_node: 0.97 seconds\n",
      "--- 4. 답변 생성 시작 ---\n",
      "생성된 답변 일부: ## 최종 해석 보고서\n",
      "\n",
      "본 보고서는 내담자가 그린 집 그림에 대한 상담사의 관찰 내용과 해석 참고 자료를 바탕으로, 내담자의 심리적 상태를 분석한 것입니다. 다음은 주요 관찰 사항과 심리적 해석을 종합한 결과입니다.\n",
      "\n",
      "### 1. 조감도 시점으로 그린 집\n",
      "\n",
      "내담자는 집을 위에서 아래로 내려다보는 조감도 시점으로 그렸습니다. 이는 현재 가정상황에 대한 불만...\n",
      "Execution time for generate_node: 11.13 seconds\n",
      "--- 5. 환각 검사 시작 ---\n",
      "환각 검사 결과: yes\n",
      "Execution time for hallucination_check_node: 0.49 seconds\n",
      "결과: 환각 없음. 최종 답변을 반환합니다.\n",
      "--- 1. 질문 관련성 검사 시작 ---\n",
      "질문 관련성: yes\n",
      "Execution time for relevance_check_node: 0.51 seconds\n",
      "결과: 관련성 있음. 질문 분해를 진행합니다.\n",
      "--- 2. 질문 분해 시작 ---\n",
      "분해된 질문: ['집 문의 크기가 비정상적으로 크다.', '집 문이 활짝 열려 있다.', '집 창문의 개수가 여러 개이며 크기가 크다.', '집 주변에 울타리가 빽빽하게 쳐져 있다.']\n",
      "Execution time for decompose_query_node: 2.69 seconds\n",
      "--- 3. 정보 검색 시작 ---\n",
      "  - 검색 쿼리: '집 문의 크기가 비정상적으로 크다.'\n",
      "  - 검색 쿼리: '집 문이 활짝 열려 있다.'\n",
      "  - 검색 쿼리: '집 창문의 개수가 여러 개이며 크기가 크다.'\n",
      "  - 검색 쿼리: '집 주변에 울타리가 빽빽하게 쳐져 있다.'\n",
      "검색된 해석 Context 수: 11\n",
      "Execution time for retrieve_node: 1.50 seconds\n",
      "--- 4. 답변 생성 시작 ---\n",
      "생성된 답변 일부: ### 최종 해석 보고서\n",
      "\n",
      "내담자의 그림에서 나타난 특징들은 그들의 심리 상태와 감정적 배경을 살펴보는 데 중요한 단서를 제공합니다. 아래에서 상담사가 관찰한 주요 그림 특징과 이에 대한 해석을 종합하여 설명하겠습니다.\n",
      "\n",
      "1. **문이 비정상적으로 크고 활짝 열려 있음**  \n",
      "   문은 외부와의 소통을 상징하며, 내담자가 세상과의 관계에서 어떤 태도를 갖고...\n",
      "Execution time for generate_node: 17.01 seconds\n",
      "--- 5. 환각 검사 시작 ---\n",
      "환각 검사 결과: yes\n",
      "Execution time for hallucination_check_node: 0.49 seconds\n",
      "결과: 환각 없음. 최종 답변을 반환합니다.\n",
      "--- 1. 질문 관련성 검사 시작 ---\n",
      "질문 관련성: yes\n",
      "Execution time for relevance_check_node: 0.72 seconds\n",
      "결과: 관련성 있음. 질문 분해를 진행합니다.\n",
      "--- 2. 질문 분해 시작 ---\n",
      "분해된 질문: ['집 문의 크기가 비정상적으로 크다.', '집 문이 활짝 열려 있다.', '집의 창문이 여러 개 있고 크기가 크다.', '집 주변에 울타리가 빽빽하게 쳐져 있다.']\n",
      "Execution time for decompose_query_node: 1.32 seconds\n",
      "--- 3. 정보 검색 시작 (카테고리: 집) ---\n",
      "  - 검색 쿼리: '집 문의 크기가 비정상적으로 크다.'\n",
      "  - 검색 쿼리: '집 문이 활짝 열려 있다.'\n",
      "  - 검색 쿼리: '집의 창문이 여러 개 있고 크기가 크다.'\n",
      "  - 검색 쿼리: '집 주변에 울타리가 빽빽하게 쳐져 있다.'\n",
      "검색된 해석 Context 수: 12\n",
      "Execution time for meta_retrieve_node: 1.77 seconds\n",
      "--- 4. 답변 생성 시작 ---\n",
      "생성된 답변 일부: ### 최종 해석 보고서\n",
      "\n",
      "본인의 그림에서 나타난 주요 특징들은 문, 창문, 그리고 벽의 크기와 형태에서 찾아볼 수 있습니다. 이 요소들은 내담자의 현재 심리적 상태와 대인관계의 특성과 욕구를 평가하는 데 중요한 단서를 제공합니다. 아래에서 각 특징에 대해 자세히 살펴보겠습니다.\n",
      "\n",
      "1. **문: 비정상적으로 크고 활짝 열려 있음**\n",
      "   - 문이 집에 비해...\n",
      "Execution time for generate_node: 17.09 seconds\n",
      "--- 5. 환각 검사 시작 ---\n",
      "환각 검사 결과: yes\n",
      "Execution time for hallucination_check_node: 5.69 seconds\n",
      "결과: 환각 없음. 최종 답변을 반환합니다.\n",
      "--- 1. 질문 관련성 검사 시작 ---\n",
      "질문 관련성: yes\n",
      "Execution time for relevance_check_node: 1.22 seconds\n",
      "결과: 관련성 있음. 질문 분해를 진행합니다.\n",
      "--- 2. 질문 분해 시작 ---\n",
      "분해된 질문: ['지붕이 생략되어 있어 벽만 그려져 있다.', '벽의 한쪽 면이 제대로 연결되지 않아 집이 무너질 것처럼 보인다.', '그림이 종이의 가장 밑바닥에 붙여서 그려져 있다.']\n",
      "Execution time for decompose_query_node: 2.08 seconds\n",
      "--- 3. 정보 검색 시작 ---\n",
      "  - 검색 쿼리: '지붕이 생략되어 있어 벽만 그려져 있다.'\n",
      "  - 검색 쿼리: '벽의 한쪽 면이 제대로 연결되지 않아 집이 무너질 것처럼 보인다.'\n",
      "  - 검색 쿼리: '그림이 종이의 가장 밑바닥에 붙여서 그려져 있다.'\n",
      "검색된 해석 Context 수: 13\n",
      "Execution time for retrieve_node: 1.16 seconds\n",
      "--- 4. 답변 생성 시작 ---\n",
      "생성된 답변 일부: ### 최종 해석 보고서\n",
      "\n",
      "이번 그림 심리검사 결과에 따르면, 내담자는 지붕이 생략된 채 벽만 그려져 있으며, 벽의 한쪽 면이 연결되지 않아 집이 무너질 것처럼 보이는 그림을 제출하였습니다. 이 그림의 특징은 여러 심리적 요소를 반영하고 있으며, 이를 종합적으로 해석해 보겠습니다.\n",
      "\n",
      "1. **지붕의 생략**: 그림에서 지붕이 생략된 것은 내담자가 자신의 내...\n",
      "Execution time for generate_node: 13.82 seconds\n",
      "--- 5. 환각 검사 시작 ---\n",
      "환각 검사 결과: yes\n",
      "Execution time for hallucination_check_node: 0.58 seconds\n",
      "결과: 환각 없음. 최종 답변을 반환합니다.\n",
      "--- 1. 질문 관련성 검사 시작 ---\n",
      "질문 관련성: yes\n",
      "Execution time for relevance_check_node: 0.48 seconds\n",
      "결과: 관련성 있음. 질문 분해를 진행합니다.\n",
      "--- 2. 질문 분해 시작 ---\n",
      "분해된 질문: ['지붕이 생략되어 벽만 그려져 있다.', '벽의 한쪽 면이 제대로 연결되지 않아 집이 무너질 것처럼 보인다.', '그림이 종이의 가장 밑바닥에 붙여서 그려져 있다.']\n",
      "Execution time for decompose_query_node: 1.74 seconds\n",
      "--- 3. 정보 검색 시작 (카테고리: 집) ---\n",
      "  - 검색 쿼리: '지붕이 생략되어 벽만 그려져 있다.'\n",
      "  - 검색 쿼리: '벽의 한쪽 면이 제대로 연결되지 않아 집이 무너질 것처럼 보인다.'\n",
      "  - 검색 쿼리: '그림이 종이의 가장 밑바닥에 붙여서 그려져 있다.'\n",
      "검색된 해석 Context 수: 12\n",
      "Execution time for meta_retrieve_node: 1.34 seconds\n",
      "--- 4. 답변 생성 시작 ---\n",
      "생성된 답변 일부: ### 최종 해석 보고서\n",
      "\n",
      "내담자가 그린 그림은 지붕이 생략된 채 벽만 그려져 있으며, 벽의 한쪽 면이 제대로 연결되지 않아 집이 무너질 것처럼 보입니다. 이 그림은 여러 심리적 측면을 반영하고 있으며, 다음과 같은 해석을 제언합니다.\n",
      "\n",
      "1. **지붕의 생략**: 지붕은 개인의 내적인 공상이나 상상을 상징합니다. 지붕이 생략된 것은 현실 검증력의 손상이나 ...\n",
      "Execution time for generate_node: 11.31 seconds\n",
      "--- 5. 환각 검사 시작 ---\n",
      "환각 검사 결과: yes\n",
      "Execution time for hallucination_check_node: 1.20 seconds\n",
      "결과: 환각 없음. 최종 답변을 반환합니다.\n",
      "--- 1. 질문 관련성 검사 시작 ---\n",
      "질문 관련성: yes\n",
      "Execution time for relevance_check_node: 4.12 seconds\n",
      "결과: 관련성 있음. 질문 분해를 진행합니다.\n",
      "--- 2. 질문 분해 시작 ---\n",
      "분해된 질문: ['나무 기둥이 매우 가늘다.', '나무 기둥은 땅에 뿌리가 없이 공중에 떠 있다.', '나뭇잎은 무성하다.', '나뭇잎의 끝이 모두 뾰족하게 그려져 있다.', '익은 열매가 여러 개 땅에 떨어져 있다.']\n",
      "Execution time for decompose_query_node: 2.53 seconds\n",
      "--- 3. 정보 검색 시작 ---\n",
      "  - 검색 쿼리: '나무 기둥이 매우 가늘다.'\n",
      "  - 검색 쿼리: '나무 기둥은 땅에 뿌리가 없이 공중에 떠 있다.'\n",
      "  - 검색 쿼리: '나뭇잎은 무성하다.'\n",
      "  - 검색 쿼리: '나뭇잎의 끝이 모두 뾰족하게 그려져 있다.'\n",
      "  - 검색 쿼리: '익은 열매가 여러 개 땅에 떨어져 있다.'\n",
      "검색된 해석 Context 수: 14\n",
      "Execution time for retrieve_node: 2.04 seconds\n",
      "--- 4. 답변 생성 시작 ---\n",
      "생성된 답변 일부: ### 최종 해석 보고서\n",
      "\n",
      "상담사가 관찰한 그림의 특징은 다음과 같습니다. 나무 기둥이 매우 가늘고, 뿌리가 없이 공중에 떠 있으며, 나뭇잎들은 무성하지만 그 끝이 모두 뾰족하게 그려져 있고, 익은 열매 여러 개가 땅에 떨어져 있습니다. 이러한 요소들은 내담자의 심리상태를 여러 측면에서 심도 있게 드러내고 있습니다.\n",
      "\n",
      "1. **나무 기둥의 가냘픔과 공중에 ...\n",
      "Execution time for generate_node: 15.88 seconds\n",
      "--- 5. 환각 검사 시작 ---\n",
      "환각 검사 결과: yes\n",
      "Execution time for hallucination_check_node: 0.65 seconds\n",
      "결과: 환각 없음. 최종 답변을 반환합니다.\n",
      "--- 1. 질문 관련성 검사 시작 ---\n",
      "질문 관련성: yes\n",
      "Execution time for relevance_check_node: 0.76 seconds\n",
      "결과: 관련성 있음. 질문 분해를 진행합니다.\n",
      "--- 2. 질문 분해 시작 ---\n",
      "분해된 질문: ['나무 기둥이 매우 가늘다.', '나무의 뿌리가 땅에 없이 공중에 떠 있다.', '나뭇잎은 무성하다.', '나뭇잎의 끝이 모두 뾰족하게 그려져 있다.', '익은 열매 여러 개가 땅에 떨어져 있다.']\n",
      "Execution time for decompose_query_node: 2.43 seconds\n",
      "--- 3. 정보 검색 시작 (카테고리: 나무) ---\n",
      "  - 검색 쿼리: '나무 기둥이 매우 가늘다.'\n",
      "  - 검색 쿼리: '나무의 뿌리가 땅에 없이 공중에 떠 있다.'\n",
      "  - 검색 쿼리: '나뭇잎은 무성하다.'\n",
      "  - 검색 쿼리: '나뭇잎의 끝이 모두 뾰족하게 그려져 있다.'\n",
      "  - 검색 쿼리: '익은 열매 여러 개가 땅에 떨어져 있다.'\n",
      "검색된 해석 Context 수: 17\n",
      "Execution time for meta_retrieve_node: 2.11 seconds\n",
      "--- 4. 답변 생성 시작 ---\n",
      "생성된 답변 일부: ### 최종 해석 보고서\n",
      "\n",
      "내담자가 그린 나무 그림은 다양한 심리적 요소를 반영하고 있습니다. 다음은 상담사가 관찰한 주요 그림 특징과 이를 바탕으로 한 해석입니다.\n",
      "\n",
      "1. **가늘고 뿌리 없는 기둥**\n",
      "   - 내담자의 나무 기둥은 매우 가늘고 뿌리가 없이 공중에 떠 있는 형태입니다. 이는 내담자가 현재 기초적인 안정감이나 자기 존재감에 대한 결여를 느끼...\n",
      "Execution time for generate_node: 14.11 seconds\n",
      "--- 5. 환각 검사 시작 ---\n",
      "환각 검사 결과: yes\n",
      "Execution time for hallucination_check_node: 0.66 seconds\n",
      "결과: 환각 없음. 최종 답변을 반환합니다.\n",
      "--- 1. 질문 관련성 검사 시작 ---\n",
      "질문 관련성: yes\n",
      "Execution time for relevance_check_node: 0.58 seconds\n",
      "결과: 관련성 있음. 질문 분해를 진행합니다.\n",
      "--- 2. 질문 분해 시작 ---\n",
      "분해된 질문: ['그림에 죽은 나무가 그려져 있으며 가지가 부러지고 잎이 하나도 없다.', '죽은 나무의 기둥에는 옹이 구멍이 있다.', '옹이 구멍 안에는 작은 동물이 숨어 있다.', '그림의 선은 전체적으로 여러 번 겹쳐서 그려진 스케치 선이다.']\n",
      "Execution time for decompose_query_node: 2.43 seconds\n",
      "--- 3. 정보 검색 시작 ---\n",
      "  - 검색 쿼리: '그림에 죽은 나무가 그려져 있으며 가지가 부러지고 잎이 하나도 없다.'\n",
      "  - 검색 쿼리: '죽은 나무의 기둥에는 옹이 구멍이 있다.'\n",
      "  - 검색 쿼리: '옹이 구멍 안에는 작은 동물이 숨어 있다.'\n",
      "  - 검색 쿼리: '그림의 선은 전체적으로 여러 번 겹쳐서 그려진 스케치 선이다.'\n",
      "검색된 해석 Context 수: 18\n",
      "Execution time for retrieve_node: 1.70 seconds\n",
      "--- 4. 답변 생성 시작 ---\n",
      "생성된 답변 일부: ### 최종 해석 보고서\n",
      "\n",
      "**내담자의 그림 분석을 통한 심리상태 해석**\n",
      "\n",
      "상담사가 관찰한 그림에서는 죽은 나무와 그 나무에 숨은 작은 동물, 겹친 선들이 나타나 있습니다. 이러한 그림 요소를 바탕으로 내담자의 심리상태를 분석해보겠습니다.\n",
      "\n",
      "1. **죽은 나무**  \n",
      "   그림의 중심인 죽은 나무는 내담자의 현재 정서적 상태와 심리적 어려움을 상징합니다....\n",
      "Execution time for generate_node: 14.70 seconds\n",
      "--- 5. 환각 검사 시작 ---\n",
      "환각 검사 결과: yes\n",
      "Execution time for hallucination_check_node: 0.95 seconds\n",
      "결과: 환각 없음. 최종 답변을 반환합니다.\n",
      "--- 1. 질문 관련성 검사 시작 ---\n",
      "질문 관련성: yes\n",
      "Execution time for relevance_check_node: 0.52 seconds\n",
      "결과: 관련성 있음. 질문 분해를 진행합니다.\n",
      "--- 2. 질문 분해 시작 ---\n",
      "분해된 질문: ['그림에는 가지가 부러지고 잎이 없는 죽은 나무가 그려져 있다.', '죽은 나무 기둥에는 옹이 구멍이 있다.', '옹이 구멍 안에는 작은 동물이 숨어 있다.', '그림의 선은 여러 번 겹쳐 그린 스케치 선이다.']\n",
      "Execution time for decompose_query_node: 1.85 seconds\n",
      "--- 3. 정보 검색 시작 (카테고리: 나무) ---\n",
      "  - 검색 쿼리: '그림에는 가지가 부러지고 잎이 없는 죽은 나무가 그려져 있다.'\n",
      "  - 검색 쿼리: '죽은 나무 기둥에는 옹이 구멍이 있다.'\n",
      "  - 검색 쿼리: '옹이 구멍 안에는 작은 동물이 숨어 있다.'\n",
      "  - 검색 쿼리: '그림의 선은 여러 번 겹쳐 그린 스케치 선이다.'\n",
      "검색된 해석 Context 수: 16\n",
      "Execution time for meta_retrieve_node: 1.92 seconds\n",
      "--- 4. 답변 생성 시작 ---\n",
      "생성된 답변 일부: ## 최종 해석 보고서\n",
      "\n",
      "이번 심리검사는 내담자가 그린 ‘죽은 나무’ 그림을 통해 내담자의 심리적 상태와 내면의 감정을 분석하였습니다. 그 과정에서 상담사가 관찰한 특징들을 바탕으로 심리적 해석을 진행하였습니다.\n",
      "\n",
      "### 1. 죽은 나무의 상징성\n",
      "내담자가 그린 죽은 나무는 ‘나는 죽은 것과 다름없음’을 상징하는 것으로, 내담자가 심리적으로 상당한 부적응 상...\n",
      "Execution time for generate_node: 17.99 seconds\n",
      "--- 5. 환각 검사 시작 ---\n",
      "환각 검사 결과: yes\n",
      "Execution time for hallucination_check_node: 1.30 seconds\n",
      "결과: 환각 없음. 최종 답변을 반환합니다.\n",
      "--- 1. 질문 관련성 검사 시작 ---\n",
      "질문 관련성: yes\n",
      "Execution time for relevance_check_node: 0.54 seconds\n",
      "결과: 관련성 있음. 질문 분해를 진행합니다.\n",
      "--- 2. 질문 분해 시작 ---\n",
      "분해된 질문: ['버드나무의 가지가 모두 아래로 축 처져 있다.', '땅 위로 드러난 뿌리가 발톱 모양으로 땅을 움켜잡고 있다.', '나뭇잎은 전혀 없고 가지는 무성하다.']\n",
      "Execution time for decompose_query_node: 1.93 seconds\n",
      "--- 3. 정보 검색 시작 ---\n",
      "  - 검색 쿼리: '버드나무의 가지가 모두 아래로 축 처져 있다.'\n",
      "  - 검색 쿼리: '땅 위로 드러난 뿌리가 발톱 모양으로 땅을 움켜잡고 있다.'\n",
      "  - 검색 쿼리: '나뭇잎은 전혀 없고 가지는 무성하다.'\n",
      "검색된 해석 Context 수: 13\n",
      "Execution time for retrieve_node: 1.48 seconds\n",
      "--- 4. 답변 생성 시작 ---\n",
      "생성된 답변 일부: ### 심리상태 해석 보고서\n",
      "\n",
      "내담자의 그림을 분석한 결과, 여러 가지 심리적 특징을 발견하였습니다. 이번 그림에서 주목해야 할 요소는 가지, 뿌리 및 나뭇잎의 표현 방식입니다.\n",
      "\n",
      "1. **버드나무 형태의 가지**:\n",
      "   - 내담자의 그림에서 나타난 가지는 아래로 축 처진 형태로, 이는 무력감과 수동적인 심리를 상징합니다. 이러한 형태는 내담자가 심적으로 ...\n",
      "Execution time for generate_node: 12.95 seconds\n",
      "--- 5. 환각 검사 시작 ---\n",
      "환각 검사 결과: yes\n",
      "Execution time for hallucination_check_node: 0.69 seconds\n",
      "결과: 환각 없음. 최종 답변을 반환합니다.\n",
      "--- 1. 질문 관련성 검사 시작 ---\n",
      "질문 관련성: yes\n",
      "Execution time for relevance_check_node: 0.80 seconds\n",
      "결과: 관련성 있음. 질문 분해를 진행합니다.\n",
      "--- 2. 질문 분해 시작 ---\n",
      "분해된 질문: ['버드나무의 가지가 모두 아래로 축 처져 있다.', '버드나무의 뿌리가 발톱 모양으로 땅을 움켜잡고 있다.', '나뭇잎은 하나도 없다.', '가지는 무성하다.']\n",
      "Execution time for decompose_query_node: 1.94 seconds\n",
      "--- 3. 정보 검색 시작 (카테고리: 나무) ---\n",
      "  - 검색 쿼리: '버드나무의 가지가 모두 아래로 축 처져 있다.'\n",
      "  - 검색 쿼리: '버드나무의 뿌리가 발톱 모양으로 땅을 움켜잡고 있다.'\n",
      "  - 검색 쿼리: '나뭇잎은 하나도 없다.'\n",
      "  - 검색 쿼리: '가지는 무성하다.'\n",
      "검색된 해석 Context 수: 16\n",
      "Execution time for meta_retrieve_node: 1.46 seconds\n",
      "--- 4. 답변 생성 시작 ---\n",
      "생성된 답변 일부: ## 최종 해석 보고서\n",
      "\n",
      "내담자의 그림에서 관찰된 특징은 가지가 모두 아래로 축 처진 버드나무 형태로, 땅 위로 드러난 뿌리가 발톱 모양으로 땅을 움켜쥐고 있다는 점입니다. 나뭇잎은 전혀 존재하지 않으며, 무성한 가지만 그려져 있습니다. 이러한 요소들은 내담자의 심리 상태를 다각도로 해석할 수 있는 단서를 제공합니다.\n",
      "\n",
      "### 1. 가지의 형태\n",
      "\n",
      "버드나무처...\n",
      "Execution time for generate_node: 17.22 seconds\n",
      "--- 5. 환각 검사 시작 ---\n",
      "환각 검사 결과: yes\n",
      "Execution time for hallucination_check_node: 0.76 seconds\n",
      "결과: 환각 없음. 최종 답변을 반환합니다.\n",
      "--- 1. 질문 관련성 검사 시작 ---\n",
      "질문 관련성: yes\n",
      "Execution time for relevance_check_node: 0.66 seconds\n",
      "결과: 관련성 있음. 질문 분해를 진행합니다.\n",
      "--- 2. 질문 분해 시작 ---\n",
      "분해된 질문: ['나무 기둥이 비정상적으로 넓고 크다.', '기둥과 가지가 1차원적인 선으로만 표현되었다.', '나뭇가지는 몇 개 없고 모두 하늘을 향해 위로 뻗어 있다.']\n",
      "Execution time for decompose_query_node: 2.48 seconds\n",
      "--- 3. 정보 검색 시작 ---\n",
      "  - 검색 쿼리: '나무 기둥이 비정상적으로 넓고 크다.'\n",
      "  - 검색 쿼리: '기둥과 가지가 1차원적인 선으로만 표현되었다.'\n",
      "  - 검색 쿼리: '나뭇가지는 몇 개 없고 모두 하늘을 향해 위로 뻗어 있다.'\n",
      "검색된 해석 Context 수: 13\n",
      "Execution time for retrieve_node: 1.40 seconds\n",
      "--- 4. 답변 생성 시작 ---\n",
      "생성된 답변 일부: ### 최종 해석 보고서\n",
      "\n",
      "상담사가 관찰한 내담자의 그림에서 나타난 여러 특성은 내담자의 심리적 상태와 문제를 이해하는 데 중요한 단서를 제공합니다.\n",
      "\n",
      "1. **나무 기둥의 비정상적인 크기**: 내담자는 나무 기둥을 비정상적으로 넓고 크게 그린 것으로 보이며, 이는 자아 강도에 대한 과도한 방어적 태도를 반영할 수 있습니다. 상담 참고자료에 따르면, 지나치...\n",
      "Execution time for generate_node: 15.41 seconds\n",
      "--- 5. 환각 검사 시작 ---\n",
      "환각 검사 결과: yes\n",
      "Execution time for hallucination_check_node: 2.17 seconds\n",
      "결과: 환각 없음. 최종 답변을 반환합니다.\n",
      "--- 1. 질문 관련성 검사 시작 ---\n",
      "질문 관련성: yes\n",
      "Execution time for relevance_check_node: 0.63 seconds\n",
      "결과: 관련성 있음. 질문 분해를 진행합니다.\n",
      "--- 2. 질문 분해 시작 ---\n",
      "분해된 질문: ['나무 기둥은 비정상적으로 넓고 크다.', '나무 기둥과 가지는 1차원적인 선으로 표현되었다.', '나뭇가지는 몇 개 없고 모두 하늘을 향해 위로 뻗어 있다.']\n",
      "Execution time for decompose_query_node: 1.82 seconds\n",
      "--- 3. 정보 검색 시작 (카테고리: 나무) ---\n",
      "  - 검색 쿼리: '나무 기둥은 비정상적으로 넓고 크다.'\n",
      "  - 검색 쿼리: '나무 기둥과 가지는 1차원적인 선으로 표현되었다.'\n",
      "  - 검색 쿼리: '나뭇가지는 몇 개 없고 모두 하늘을 향해 위로 뻗어 있다.'\n",
      "검색된 해석 Context 수: 10\n",
      "Execution time for meta_retrieve_node: 1.99 seconds\n",
      "--- 4. 답변 생성 시작 ---\n",
      "생성된 답변 일부: ## 최종 해석 보고서\n",
      "\n",
      "상담사가 관찰한 내담자의 나무 그림에는 몇 가지 두드러진 특징이 있으며, 이를 통해 내담자의 심리상태를 분석하고 해석해보겠습니다.\n",
      "\n",
      "1. **나무 기둥의 비정상적인 크기**: 내담자가 그린 나무 기둥이 비정상적으로 넓고 큰 특성은 자아 강도와 내면화된 자기대상에 대한 복잡한 심리를 반영합니다. 일반적으로 지나치게 큰 나무 기둥은 내...\n",
      "Execution time for generate_node: 14.64 seconds\n",
      "--- 5. 환각 검사 시작 ---\n",
      "환각 검사 결과: yes\n",
      "Execution time for hallucination_check_node: 0.73 seconds\n",
      "결과: 환각 없음. 최종 답변을 반환합니다.\n",
      "--- 1. 질문 관련성 검사 시작 ---\n",
      "질문 관련성: yes\n",
      "Execution time for relevance_check_node: 0.54 seconds\n",
      "결과: 관련성 있음. 질문 분해를 진행합니다.\n",
      "--- 2. 질문 분해 시작 ---\n",
      "분해된 질문: ['종이의 오른쪽 상단 구석에 아주 작은 나무가 그려져 있다.', '나무의 나이는 100살이다.', '나무 기둥에 오물이 묻어 있다.']\n",
      "Execution time for decompose_query_node: 1.37 seconds\n",
      "--- 3. 정보 검색 시작 ---\n",
      "  - 검색 쿼리: '종이의 오른쪽 상단 구석에 아주 작은 나무가 그려져 있다.'\n",
      "  - 검색 쿼리: '나무의 나이는 100살이다.'\n",
      "  - 검색 쿼리: '나무 기둥에 오물이 묻어 있다.'\n",
      "검색된 해석 Context 수: 13\n",
      "Execution time for retrieve_node: 1.22 seconds\n",
      "--- 4. 답변 생성 시작 ---\n",
      "생성된 답변 일부: ### 최종 해석 보고서\n",
      "\n",
      "내담자가 그린 그림은 오른쪽 상단 구석에 아주 작은 나무로 구성되어 있으며, 이 나무는 100살로 표현되었고 그 기둥에는 오물이 묻어 있는 특징이 있습니다. 이러한 요소들은 내담자의 심리적 상태와 정서적 갈등을 반영한다고 해석될 수 있습니다.\n",
      "\n",
      "1. **작은 나무의 크기**: 그림에서 나무가 매우 작게 그려진 것은 내담자가 내면에...\n",
      "Execution time for generate_node: 12.42 seconds\n",
      "--- 5. 환각 검사 시작 ---\n",
      "환각 검사 결과: yes\n",
      "Execution time for hallucination_check_node: 0.65 seconds\n",
      "결과: 환각 없음. 최종 답변을 반환합니다.\n",
      "--- 1. 질문 관련성 검사 시작 ---\n",
      "질문 관련성: yes\n",
      "Execution time for relevance_check_node: 0.85 seconds\n",
      "결과: 관련성 있음. 질문 분해를 진행합니다.\n",
      "--- 2. 질문 분해 시작 ---\n",
      "분해된 질문: ['종이의 오른쪽 상단 구석에 아주 작은 나무가 그려져 있다.', '나무의 나이는 100살이다.', '나무 기둥에 오물이 묻어 있다.']\n",
      "Execution time for decompose_query_node: 2.00 seconds\n",
      "--- 3. 정보 검색 시작 (카테고리: 나무) ---\n",
      "  - 검색 쿼리: '종이의 오른쪽 상단 구석에 아주 작은 나무가 그려져 있다.'\n",
      "  - 검색 쿼리: '나무의 나이는 100살이다.'\n",
      "  - 검색 쿼리: '나무 기둥에 오물이 묻어 있다.'\n",
      "검색된 해석 Context 수: 14\n",
      "Execution time for meta_retrieve_node: 1.22 seconds\n",
      "--- 4. 답변 생성 시작 ---\n",
      "생성된 답변 일부: ### 최종 해석 보고서\n",
      "\n",
      "상담사가 관찰한 내담자의 그림 특징에서 몇 가지 주요한 요소를 확인할 수 있으며, 이는 내담자의 심리적 상태와 관련된 중요한 정보를 제공합니다.\n",
      "\n",
      "1. **그림의 위치 - 오른쪽 상단 구석**  \n",
      "   내담자는 그림을 종이의 오른쪽 상단 구석에 그렸습니다. 이는 일반적으로 내담자가 불쾌한 과거 기억을 억압하고자 하는 의지, 또는 ...\n",
      "Execution time for generate_node: 12.55 seconds\n",
      "--- 5. 환각 검사 시작 ---\n",
      "환각 검사 결과: yes\n",
      "Execution time for hallucination_check_node: 0.69 seconds\n",
      "결과: 환각 없음. 최종 답변을 반환합니다.\n",
      "--- 1. 질문 관련성 검사 시작 ---\n",
      "질문 관련성: yes\n",
      "Execution time for relevance_check_node: 0.71 seconds\n",
      "결과: 관련성 있음. 질문 분해를 진행합니다.\n",
      "--- 2. 질문 분해 시작 ---\n",
      "분해된 질문: ['사람의 머리 크기가 신체에 비해 지나치게 크다.', '사람의 얼굴에 눈이 아주 작게 표현되었다.', '사람의 입은 생략되었다.', '사람의 팔이 매우 길고 가늘다.', '사람의 손은 그려져 있지 않다.']\n",
      "Execution time for decompose_query_node: 1.69 seconds\n",
      "--- 3. 정보 검색 시작 ---\n",
      "  - 검색 쿼리: '사람의 머리 크기가 신체에 비해 지나치게 크다.'\n",
      "  - 검색 쿼리: '사람의 얼굴에 눈이 아주 작게 표현되었다.'\n",
      "  - 검색 쿼리: '사람의 입은 생략되었다.'\n",
      "  - 검색 쿼리: '사람의 팔이 매우 길고 가늘다.'\n",
      "  - 검색 쿼리: '사람의 손은 그려져 있지 않다.'\n",
      "검색된 해석 Context 수: 18\n",
      "Execution time for retrieve_node: 2.07 seconds\n",
      "--- 4. 답변 생성 시작 ---\n",
      "생성된 답변 일부: ## 최종 해석 보고서\n",
      "\n",
      "본 보고서는 내담자의 HTP 그림 심리검사를 바탕으로 내담자의 심리상태를 종합적으로 분석하여 작성되었습니다. 그림의 특징은 다음과 같습니다: 머리가 신체에 비해 지나치게 크고, 얼굴의 눈은 아주 작게 표현되었으며 입은 생략되었습니다. 팔은 길고 가늘지만 손은 그려지지 않았습니다.\n",
      "\n",
      "### 1. 머리의 크기\n",
      "내담자가 머리를 지나치게 ...\n",
      "Execution time for generate_node: 9.63 seconds\n",
      "--- 5. 환각 검사 시작 ---\n",
      "환각 검사 결과: yes\n",
      "Execution time for hallucination_check_node: 0.88 seconds\n",
      "결과: 환각 없음. 최종 답변을 반환합니다.\n",
      "--- 1. 질문 관련성 검사 시작 ---\n",
      "질문 관련성: yes\n",
      "Execution time for relevance_check_node: 0.53 seconds\n",
      "결과: 관련성 있음. 질문 분해를 진행합니다.\n",
      "--- 2. 질문 분해 시작 ---\n",
      "분해된 질문: ['사람의 머리가 신체에 비해 지나치게 크다.', '사람의 얼굴에 눈이 아주 작게 표현되었다.', '사람의 입은 생략되었다.', '사람의 팔은 매우 길고 가늘다.', '사람의 손은 그려져 있지 않다.']\n",
      "Execution time for decompose_query_node: 2.86 seconds\n",
      "--- 3. 정보 검색 시작 (카테고리: 사람) ---\n",
      "  - 검색 쿼리: '사람의 머리가 신체에 비해 지나치게 크다.'\n",
      "  - 검색 쿼리: '사람의 얼굴에 눈이 아주 작게 표현되었다.'\n",
      "  - 검색 쿼리: '사람의 입은 생략되었다.'\n",
      "  - 검색 쿼리: '사람의 팔은 매우 길고 가늘다.'\n",
      "  - 검색 쿼리: '사람의 손은 그려져 있지 않다.'\n",
      "검색된 해석 Context 수: 15\n",
      "Execution time for meta_retrieve_node: 1.83 seconds\n",
      "--- 4. 답변 생성 시작 ---\n",
      "생성된 답변 일부: ### 최종 해석 보고서\n",
      "\n",
      "본인의 그림을 통해 관찰된 특징은 다음과 같습니다: 머리가 신체에 비해 지나치게 크고, 얼굴 특징은 매우 간략하며, 팔은 길고 가늘지만 손은 그려지지 않았습니다. 이 관찰 결과를 바탕으로 내담자의 심리상태를 분석해 보겠습니다.\n",
      "\n",
      "1. **대두(大頭)의 표현**: 머리가 신체에 비해 지나치게 크다는 것은 일반적으로 두 가지 해석이 ...\n",
      "Execution time for generate_node: 13.26 seconds\n",
      "--- 5. 환각 검사 시작 ---\n",
      "환각 검사 결과: yes\n",
      "Execution time for hallucination_check_node: 0.86 seconds\n",
      "결과: 환각 없음. 최종 답변을 반환합니다.\n",
      "--- 1. 질문 관련성 검사 시작 ---\n",
      "질문 관련성: yes\n",
      "Execution time for relevance_check_node: 0.41 seconds\n",
      "결과: 관련성 있음. 질문 분해를 진행합니다.\n",
      "--- 2. 질문 분해 시작 ---\n",
      "분해된 질문: ['그림에는 사람의 뒷모습만 그려져 있다.', '사람의 어깨가 매우 넓게 강조되어 있다.', '인물은 가는 지면선 위에 서 있다.', '전체적으로 필압이 매우 강하게 드러나 있다.']\n",
      "Execution time for decompose_query_node: 1.73 seconds\n",
      "--- 3. 정보 검색 시작 ---\n",
      "  - 검색 쿼리: '그림에는 사람의 뒷모습만 그려져 있다.'\n",
      "  - 검색 쿼리: '사람의 어깨가 매우 넓게 강조되어 있다.'\n",
      "  - 검색 쿼리: '인물은 가는 지면선 위에 서 있다.'\n",
      "  - 검색 쿼리: '전체적으로 필압이 매우 강하게 드러나 있다.'\n",
      "검색된 해석 Context 수: 21\n",
      "Execution time for retrieve_node: 1.46 seconds\n",
      "--- 4. 답변 생성 시작 ---\n",
      "생성된 답변 일부: ### 최종 해석 보고서\n",
      "\n",
      "이번 HTP 그림 심리검사 결과를 바탕으로 내담자의 심리상태를 분석한 결과는 다음과 같습니다. 상담사는 사람 그림의 뒷모습을 그리도록 한 내담자가 어깨를 강조하고, 강한 필압으로 그림을 그린 것을 주목하였습니다. 이를 통해 내담자의 심리적 상태와 심리적 특성을 유추할 수 있습니다.\n",
      "\n",
      "1. **인물의 뒷모습과 어깨 강조**:\n",
      "   ...\n",
      "Execution time for generate_node: 14.19 seconds\n",
      "--- 5. 환각 검사 시작 ---\n",
      "환각 검사 결과: yes\n",
      "Execution time for hallucination_check_node: 0.65 seconds\n",
      "결과: 환각 없음. 최종 답변을 반환합니다.\n",
      "--- 1. 질문 관련성 검사 시작 ---\n",
      "질문 관련성: yes\n",
      "Execution time for relevance_check_node: 0.56 seconds\n",
      "결과: 관련성 있음. 질문 분해를 진행합니다.\n",
      "--- 2. 질문 분해 시작 ---\n",
      "분해된 질문: ['그림에는 사람의 뒷모습만 그려져 있다.', '인물의 어깨가 매우 넓게 강조되어 있다.', '인물은 가는 지면선 위에 서 있다.', '전체적으로 필압이 매우 강하다.']\n",
      "Execution time for decompose_query_node: 1.85 seconds\n",
      "--- 3. 정보 검색 시작 (카테고리: 사람) ---\n",
      "  - 검색 쿼리: '그림에는 사람의 뒷모습만 그려져 있다.'\n",
      "  - 검색 쿼리: '인물의 어깨가 매우 넓게 강조되어 있다.'\n",
      "  - 검색 쿼리: '인물은 가는 지면선 위에 서 있다.'\n",
      "  - 검색 쿼리: '전체적으로 필압이 매우 강하다.'\n",
      "검색된 해석 Context 수: 18\n",
      "Execution time for meta_retrieve_node: 1.47 seconds\n",
      "--- 4. 답변 생성 시작 ---\n",
      "생성된 답변 일부: ### 최종 해석 보고서\n",
      "\n",
      "상담사가 관찰한 그림에서 내담자는 사람의 뒷모습만 그리며, 어깨를 매우 넓게 강조하고, 가는 지면선 위에서 서 있는 모습을 표현하였습니다. 전체적으로 필압이 매우 강하게 나타난 점도 눈에 띕니다. 이러한 특징들을 해석해보면 내담자의 심리 상태와 내적 갈등을 통찰할 수 있습니다.\n",
      "\n",
      "1. **뒷모습의 선택**:\n",
      "   내담자가 사람의 ...\n",
      "Execution time for generate_node: 14.05 seconds\n",
      "--- 5. 환각 검사 시작 ---\n",
      "환각 검사 결과: yes\n",
      "Execution time for hallucination_check_node: 0.85 seconds\n",
      "결과: 환각 없음. 최종 답변을 반환합니다.\n",
      "--- 1. 질문 관련성 검사 시작 ---\n",
      "질문 관련성: yes\n",
      "Execution time for relevance_check_node: 0.59 seconds\n",
      "결과: 관련성 있음. 질문 분해를 진행합니다.\n",
      "--- 2. 질문 분해 시작 ---\n",
      "분해된 질문: ['머리와 몸통이 바로 붙어 있어 목이 생략되었다.', '팔은 짧고 몸통에 바짝 붙어 있다.', '손은 주먹을 꽉 쥔 형태로 그려져 있다.', '다리는 넓게 벌리고 서 있다.']\n",
      "Execution time for decompose_query_node: 1.73 seconds\n",
      "--- 3. 정보 검색 시작 ---\n",
      "  - 검색 쿼리: '머리와 몸통이 바로 붙어 있어 목이 생략되었다.'\n",
      "  - 검색 쿼리: '팔은 짧고 몸통에 바짝 붙어 있다.'\n",
      "  - 검색 쿼리: '손은 주먹을 꽉 쥔 형태로 그려져 있다.'\n",
      "  - 검색 쿼리: '다리는 넓게 벌리고 서 있다.'\n",
      "검색된 해석 Context 수: 16\n",
      "Execution time for retrieve_node: 1.55 seconds\n",
      "--- 4. 답변 생성 시작 ---\n",
      "생성된 답변 일부: ### 최종 해석 보고서\n",
      "\n",
      "내담자께서 그린 그림은 여러 특성을 통해 심리상태를 분석할 수 있는 정보를 제공합니다. 아래에서 각 특징과 그에 대한 해석을 종합적으로 다루도록 하겠습니다.\n",
      "\n",
      "1. **머리와 몸통의 생략**:\n",
      "   머리와 몸통이 바로 붙어 있어 목이 생략된 것은 중요한 정서적 의미를 가지고 있습니다. 이는 일반적으로 사고장애나 신경학적 장애의 가...\n",
      "Execution time for generate_node: 14.39 seconds\n",
      "--- 5. 환각 검사 시작 ---\n",
      "환각 검사 결과: yes\n",
      "Execution time for hallucination_check_node: 1.00 seconds\n",
      "결과: 환각 없음. 최종 답변을 반환합니다.\n",
      "--- 1. 질문 관련성 검사 시작 ---\n",
      "질문 관련성: yes\n",
      "Execution time for relevance_check_node: 0.48 seconds\n",
      "결과: 관련성 있음. 질문 분해를 진행합니다.\n",
      "--- 2. 질문 분해 시작 ---\n",
      "분해된 질문: ['머리와 몸통이 바로 붙어 있어 목이 생략되었다.', '팔은 짧고 몸통에 바짝 붙어 있다.', '손은 주먹을 꽉 쥔 형태로 그려져 있다.', '다리는 넓게 벌리고 서 있다.']\n",
      "Execution time for decompose_query_node: 2.60 seconds\n",
      "--- 3. 정보 검색 시작 (카테고리: 사람) ---\n",
      "  - 검색 쿼리: '머리와 몸통이 바로 붙어 있어 목이 생략되었다.'\n",
      "  - 검색 쿼리: '팔은 짧고 몸통에 바짝 붙어 있다.'\n",
      "  - 검색 쿼리: '손은 주먹을 꽉 쥔 형태로 그려져 있다.'\n",
      "  - 검색 쿼리: '다리는 넓게 벌리고 서 있다.'\n",
      "검색된 해석 Context 수: 15\n",
      "Execution time for meta_retrieve_node: 2.42 seconds\n",
      "--- 4. 답변 생성 시작 ---\n",
      "생성된 답변 일부: ### 최종 해석 보고서\n",
      "\n",
      "본 검사는 내담자가 그린 그림을 토대로 그들의 심리적 상태와 인지적 특성을 분석한 결과를 담고 있습니다. 상담사가 관찰한 그림의 주요 특징들과 그에 대한 해석 참고자료를 바탕으로 내담자의 심리적 특징을 종합적으로 살펴보겠습니다.\n",
      "\n",
      "#### 1. 신체적 특징의 관찰\n",
      "내담자는 머리와 몸통이 바로 붙어 있고 목이 생략된 형태로 인물을 ...\n",
      "Execution time for generate_node: 12.49 seconds\n",
      "--- 5. 환각 검사 시작 ---\n",
      "환각 검사 결과: yes\n",
      "Execution time for hallucination_check_node: 0.62 seconds\n",
      "결과: 환각 없음. 최종 답변을 반환합니다.\n",
      "--- 1. 질문 관련성 검사 시작 ---\n",
      "질문 관련성: yes\n",
      "Execution time for relevance_check_node: 0.56 seconds\n",
      "결과: 관련성 있음. 질문 분해를 진행합니다.\n",
      "--- 2. 질문 분해 시작 ---\n",
      "분해된 질문: ['사람의 모습이 광대처럼 우스꽝스럽다.', '사람의 옷에는 단추가 세로로 길게 달려 있다.', '사람의 신체에 비해 넥타이가 매우 크고 화려하다.']\n",
      "Execution time for decompose_query_node: 1.75 seconds\n",
      "--- 3. 정보 검색 시작 ---\n",
      "  - 검색 쿼리: '사람의 모습이 광대처럼 우스꽝스럽다.'\n",
      "  - 검색 쿼리: '사람의 옷에는 단추가 세로로 길게 달려 있다.'\n",
      "  - 검색 쿼리: '사람의 신체에 비해 넥타이가 매우 크고 화려하다.'\n",
      "검색된 해석 Context 수: 14\n",
      "Execution time for retrieve_node: 1.05 seconds\n",
      "--- 4. 답변 생성 시작 ---\n",
      "생성된 답변 일부: ## 최종 해석 보고서\n",
      "\n",
      "본 보고서는 내담자가 그린 그림의 특징을 바탕으로 심리상태를 해석한 것입니다. 상담사가 관찰한 '그림 특징'과 '해석 참고자료'를 종합하여 작성하였습니다.\n",
      "\n",
      "### 1. 자아 표현 형식\n",
      "내담자가 그린 그림은 광대처럼 우스꽝스러운 모습을 한 사람으로, 이는 내담자의 현재 심리상태에서 자아 인식과 감정이 표현된 것으로 보입니다. 광대의...\n",
      "Execution time for generate_node: 16.27 seconds\n",
      "--- 5. 환각 검사 시작 ---\n",
      "환각 검사 결과: yes\n",
      "Execution time for hallucination_check_node: 0.84 seconds\n",
      "결과: 환각 없음. 최종 답변을 반환합니다.\n",
      "--- 1. 질문 관련성 검사 시작 ---\n",
      "질문 관련성: yes\n",
      "Execution time for relevance_check_node: 0.55 seconds\n",
      "결과: 관련성 있음. 질문 분해를 진행합니다.\n",
      "--- 2. 질문 분해 시작 ---\n",
      "분해된 질문: ['그림에는 광대처럼 우스꽝스러운 모습의 사람이 그려져 있다.', '사람의 옷에는 단추가 세로로 길게 달려 있다.', '사람의 신체에 비해 매우 크고 화려한 넥타이를 매고 있다.']\n",
      "Execution time for decompose_query_node: 1.74 seconds\n",
      "--- 3. 정보 검색 시작 (카테고리: 사람) ---\n",
      "  - 검색 쿼리: '그림에는 광대처럼 우스꽝스러운 모습의 사람이 그려져 있다.'\n",
      "  - 검색 쿼리: '사람의 옷에는 단추가 세로로 길게 달려 있다.'\n",
      "  - 검색 쿼리: '사람의 신체에 비해 매우 크고 화려한 넥타이를 매고 있다.'\n",
      "검색된 해석 Context 수: 16\n",
      "Execution time for meta_retrieve_node: 2.71 seconds\n",
      "--- 4. 답변 생성 시작 ---\n",
      "생성된 답변 일부: ### 최종 해석 보고서\n",
      "\n",
      "이 내담자는 그림을 통해 우스꽝스러운 모습의 사람을 그렸습니다. 이 그림에서 몇 가지 중요한 특징이 나타납니다. 첫째, 그린 인물은 자신감을 과시하기 위한 것처럼 보이는 넥타이를 매고 있으며, 이는 그의 자아 이미지에서의 복잡한 감정을 반영합니다.  고른 드레스 스타일에 대한 관심과 함께 과장된 넥타이의 묘사는 청년기의 자아 정립...\n",
      "Execution time for generate_node: 15.00 seconds\n",
      "--- 5. 환각 검사 시작 ---\n",
      "환각 검사 결과: yes\n",
      "Execution time for hallucination_check_node: 0.59 seconds\n",
      "결과: 환각 없음. 최종 답변을 반환합니다.\n",
      "--- 1. 질문 관련성 검사 시작 ---\n",
      "질문 관련성: yes\n",
      "Execution time for relevance_check_node: 0.64 seconds\n",
      "결과: 관련성 있음. 질문 분해를 진행합니다.\n",
      "--- 2. 질문 분해 시작 ---\n",
      "분해된 질문: ['그림의 몸통이 매우 작고 왜소하게 그려졌다.', '가슴 부분이 비정상적으로 크게 강조되어 있다.', '허리에는 벨트가 강하게 졸라매져 있다.', '발이 아주 작게 그려져 있어 서 있기 불안정해 보인다.']\n",
      "Execution time for decompose_query_node: 1.73 seconds\n",
      "--- 3. 정보 검색 시작 ---\n",
      "  - 검색 쿼리: '그림의 몸통이 매우 작고 왜소하게 그려졌다.'\n",
      "  - 검색 쿼리: '가슴 부분이 비정상적으로 크게 강조되어 있다.'\n",
      "  - 검색 쿼리: '허리에는 벨트가 강하게 졸라매져 있다.'\n",
      "  - 검색 쿼리: '발이 아주 작게 그려져 있어 서 있기 불안정해 보인다.'\n",
      "검색된 해석 Context 수: 19\n",
      "Execution time for retrieve_node: 1.23 seconds\n",
      "--- 4. 답변 생성 시작 ---\n",
      "생성된 답변 일부: ### 최종 해석 보고서\n",
      "\n",
      "검사 결과에 대한 심리적 해석을 제공하겠습니다. 이 보고서는 그림 특징 관찰 내용에 기초하여 내담자의 심리 상태를 다각도로 분석한 것입니다.\n",
      "\n",
      "1. **몸통이 왜소하고 가슴이 강조됨**: 몸통이 작게 그려진 것은 내담자가 자신의 힘이나 능력에 대한 불안감이나 위축감을 느끼고 있음을 나타낼 수 있습니다. 이는 자아 강도가 낮고, 자...\n",
      "Execution time for generate_node: 10.57 seconds\n",
      "--- 5. 환각 검사 시작 ---\n",
      "환각 검사 결과: yes\n",
      "Execution time for hallucination_check_node: 0.67 seconds\n",
      "결과: 환각 없음. 최종 답변을 반환합니다.\n",
      "--- 1. 질문 관련성 검사 시작 ---\n",
      "질문 관련성: yes\n",
      "Execution time for relevance_check_node: 0.69 seconds\n",
      "결과: 관련성 있음. 질문 분해를 진행합니다.\n",
      "--- 2. 질문 분해 시작 ---\n",
      "분해된 질문: ['몸통이 매우 작고 왜소하게 그려져 있다.', '가슴이 비정상적으로 크게 강조되어 있다.', '허리에 벨트가 강하게 졸라매져 있다.', '발이 아주 작게 그려져 있어 서 있기 불안정해 보인다.']\n",
      "Execution time for decompose_query_node: 1.50 seconds\n",
      "--- 3. 정보 검색 시작 (카테고리: 사람) ---\n",
      "  - 검색 쿼리: '몸통이 매우 작고 왜소하게 그려져 있다.'\n",
      "  - 검색 쿼리: '가슴이 비정상적으로 크게 강조되어 있다.'\n",
      "  - 검색 쿼리: '허리에 벨트가 강하게 졸라매져 있다.'\n",
      "  - 검색 쿼리: '발이 아주 작게 그려져 있어 서 있기 불안정해 보인다.'\n",
      "검색된 해석 Context 수: 17\n",
      "Execution time for meta_retrieve_node: 1.56 seconds\n",
      "--- 4. 답변 생성 시작 ---\n",
      "생성된 답변 일부: ## 최종 해석 보고서:\n",
      "\n",
      "이번 HTP 그림 심리검사 결과에 따르면, 내담자의 그림에서 보이는 몇 가지 두드러진 특징이 있습니다. 주요 특징으로는 몸통이 매우 작고 왜소하게 그려진 반면, 가슴은 비정상적으로 크게 강조되었으며, 허리에는 벨트가 강하게 졸라매어 있고, 발은 아주 작게 그려져서 불안정해 보인다는 점입니다.\n",
      "\n",
      "### 1. 몸통의 크기\n",
      "내담자의 몸...\n",
      "Execution time for generate_node: 16.28 seconds\n",
      "--- 5. 환각 검사 시작 ---\n",
      "환각 검사 결과: yes\n",
      "Execution time for hallucination_check_node: 1.03 seconds\n",
      "결과: 환각 없음. 최종 답변을 반환합니다.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(\"LLMjudgeQAset.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    judge_qa_set_json = json.load(f)\n",
    "\n",
    "final_judge_result = []  # 초기화\n",
    "\n",
    "for qa in judge_qa_set_json:\n",
    "    inputs = {\"original_question\": qa[\"original_question\"], \"category\": qa[\"category\"]}\n",
    "\n",
    "    config = {\n",
    "        \"configurable\": {\n",
    "            \"faiss_store\": faiss_store,  # 초기화 단계에서 생성한 faiss_store 객체\n",
    "            \"bm25_retriever_cache\": bm25_retriever_cache,  # 초기화 단계에서 생성한 bm25_retriever_cache 객체\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # 1. Graph RAG 실행\n",
    "    graph_result = graph_app.invoke(inputs, config=config)\n",
    "\n",
    "    # 2. Meta Graph RAG 실행\n",
    "    meta_graph_result = graph_meta_app.invoke(inputs, config=config)\n",
    "\n",
    "    # 3. LLM 평가 실행\n",
    "    temp = evaluate_rag_outputs(\n",
    "        question=inputs[\"original_question\"],\n",
    "        result_A=graph_result,\n",
    "        result_B=meta_graph_result,\n",
    "    )\n",
    "\n",
    "    final_judge_result.append(temp)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "42959d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph RAG이 더 우수한 답변을 한 비율: 93.33%\n",
      "Meta Graph RAG이 더 우수한 답변을 한 비율: 6.67%\n"
     ]
    }
   ],
   "source": [
    "A = 0\n",
    "B = 0\n",
    "\n",
    "for jud_res in final_judge_result:\n",
    "    if jud_res[\"better_answer\"] == \"A\":\n",
    "        A += 1\n",
    "    elif jud_res[\"better_answer\"] == \"B\":\n",
    "        B += 1\n",
    "\n",
    "print(f\"Graph RAG이 더 우수한 답변을 한 비율: {A / len(final_judge_result) * 100:.2f}%\")\n",
    "print(f\"Meta Graph RAG이 더 우수한 답변을 한 비율: {B / len(final_judge_result) * 100:.2f}%\")\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
