{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b69f1832",
   "metadata": {},
   "source": [
    "# 패키지 설치\n",
    "1. langchain\n",
    "2. faiss-cpu\n",
    "3. Chroma\n",
    "4. python-docx\n",
    "5. dotenv\n",
    "6. openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cea8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain langchain-openai langchain-chroma langchain-community openai faiss-cpu python-docx dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74fd762",
   "metadata": {},
   "source": [
    "## 환경 변수 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e720ae86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file_path: Structural_Interpretation.docx\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "\n",
    "import os\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"OPENAI_API_BASE\"] = os.getenv(\"OPENAI_API_BASE\")\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-small\",\n",
    ")\n",
    "\n",
    "faiss_store = FAISS.load_local(\"faiss_store\", embeddings=embeddings, allow_dangerous_deserialization=True) if os.path.exists(\"faiss_store\") else None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0a6629",
   "metadata": {},
   "source": [
    "## 문서 로딩\n",
    "- docx 문서 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896d2e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from docx import Document as DocxDocument\n",
    "\n",
    "\n",
    "\n",
    "def load_docx(file_path) -> str:\n",
    "    try:\n",
    "        \"\"\"\n",
    "        문서 파일 읽고 텍스트로 변환\n",
    "        \"\"\"\n",
    "        doc = DocxDocument(file_path)\n",
    "        text = []\n",
    "        for para in doc.paragraphs:\n",
    "            text.append(para.text)\n",
    "        \n",
    "        print(f\"loaded : {file_path}\")\n",
    "\n",
    "        return \"\\n\".join(text)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {file_path}: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "full_text = load_docx(file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4e04ec",
   "metadata": {},
   "source": [
    "# 데이터 청킹\n",
    "### 문서 구조\n",
    "- [] 대괄호 category\n",
    "- {} 중괄호 소분류 \n",
    "\n",
    "해당 분류 기준을 중심으로 chunking\n",
    "## WHY ? \n",
    "1. 분류를 메타데이터로 정확도 향상\n",
    "2. 의미기반 chunking 으로 노이즈 없는 store구성을 위해서"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737fe730",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문서 저장소\n",
    "# 문서는 [] 로 대주제, {}로 소주제로 나뉘어져 있음 기준으로 청킹\n",
    "import re\n",
    "from langchain_core.documents import Document\n",
    "from pprint import pprint\n",
    "\n",
    "chunks = [] # 청크 저장소\n",
    "main_topic = None # 대주제\n",
    "sub_topic = None # 소주제\n",
    "content = [] # 본문\n",
    "\n",
    "def add_chunk(main, sub, content):\n",
    "    \"\"\"\n",
    "    청크를 추가하는 함수\n",
    "    \"\"\"\n",
    "    if main and content:\n",
    "        chunks.append(\n",
    "            Document(\n",
    "                page_content=\" \".join(content).strip(),\n",
    "                metadata={\"main_topic\": main, \"sub_topic\": sub},\n",
    "            )\n",
    "        )\n",
    "\n",
    "# 청킹\n",
    "\"\"\"\n",
    "각 주제가 바뀌는 [], {} 단위로 청크를 나누고 저장\n",
    "문서 구조) \n",
    "[대주제1]\n",
    "{소주제1}\n",
    "내용1\n",
    "내용2\n",
    "{소주제2}\n",
    "내용3\n",
    "\n",
    "\"\"\"\n",
    "try:\n",
    "    for line in full_text.split(\"\\n\"):\n",
    "        line = line.strip()\n",
    "        # 빈줄\n",
    "        if not line:\n",
    "            continue\n",
    "        # 대주제\n",
    "        if re.match(r\"^\\[.*\\]$\", line):\n",
    "            # 이전 청크 저장\n",
    "            add_chunk(main_topic, sub_topic, content)\n",
    "\n",
    "            content = []\n",
    "            main_topic = line[1:-1].strip()\n",
    "            sub_topic = None\n",
    "            continue\n",
    "        # 소주제\n",
    "        if re.match(r\"^\\{.*\\}$\", line):\n",
    "            # 이전 청크 저장\n",
    "            add_chunk(main_topic, sub_topic, content)\n",
    "            content = []\n",
    "            sub_topic = line[1:-1].strip()\n",
    "            continue\n",
    "        # 내용\n",
    "        content.append(line)\n",
    "    # 마지막 청크 저장\n",
    "    add_chunk(main_topic, sub_topic, content)\n",
    "    print(f\"Total chunks: {len(chunks)}\")\n",
    "    print(\"✅ done\")\n",
    "except Exception as e:\n",
    "    print(f\"Error during chunking: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234509ce",
   "metadata": {},
   "source": [
    "# 청크 임베딩\n",
    "## vectorDB\n",
    "### FAISS, ChromaDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5286060",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "# 임베딩모델 설정\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-small\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2c177f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# 벡터 저장소 로드\n",
    "import time\n",
    "\n",
    "batch_size = 10  # 한번에 처리할 chunk 개수 (필요시 조절)\n",
    "all_chunks = chunks  # chunks는 이미 정의되어 있는 리스트\n",
    "\n",
    "# faiss_store\n",
    "faiss_store = FAISS.load_local(\"faiss_store\", embeddings=embeddings, allow_dangerous_deserialization=True) if os.path.exists(\"faiss_store\") else None\n",
    "\n",
    "if faiss_store is None:\n",
    "    print(\"FAISS store 생성 시작\")\n",
    "    for i in range(0, len(all_chunks), batch_size):\n",
    "        batch = all_chunks[i:i + batch_size]\n",
    "        # 벡터스토어 생성 및 추가\n",
    "        if faiss_store is None:\n",
    "            faiss_store = FAISS.from_documents(batch, embedding=embeddings)\n",
    "        else:\n",
    "            faiss_store.add_documents(batch)\n",
    "        # 요청 속도 제한에 대비하여 딜레이 추가\n",
    "        time.sleep(1)\n",
    "    else:\n",
    "        print(\"생성 완료\")\n",
    "else:\n",
    "    print(\"FAISS store 로드 완료\")\n",
    "\n",
    "# chroma_store\n",
    "chroma_store = Chroma(persist_directory=\"chroma_store\", embedding_function=embeddings) if os.path.exists(\"chroma_store\") else None\n",
    "\n",
    "if chroma_store is None:\n",
    "    print(\"ChromaDB 생성 시작\")\n",
    "    for i in range(0, len(all_chunks), batch_size):\n",
    "        batch = all_chunks[i:i + batch_size]\n",
    "        # 벡터스토어 생성 및 추가\n",
    "        if chroma_store is None:\n",
    "            chroma_store = Chroma.from_documents(batch, embedding=embeddings, persist_directory=\"chroma_store\")\n",
    "        else:\n",
    "            chroma_store.add_documents(batch)\n",
    "        # 요청 속도 제한에 대비하여 딜레이 추가\n",
    "        time.sleep(1)\n",
    "    else:\n",
    "        print(\"생성 완료\")\n",
    "\n",
    "else:\n",
    "    print(\"ChromaDB 로드 완료\")\n",
    "        \n",
    "    \n",
    "print(\"✅done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d1434b",
   "metadata": {},
   "source": [
    "### TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3643a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모든 청크의 내용과 메타데이터 확인\n",
    "# for doc in chroma_store.similarity_search(\"오른쪽으로 치우쳐짐\", k=4):\n",
    "#     print(doc.page_content, doc.metadata)\n",
    "\n",
    "print(chroma_store._collection.count())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7255f028",
   "metadata": {},
   "source": [
    "# save store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41db533",
   "metadata": {},
   "outputs": [],
   "source": [
    "faiss_store.save_local(\"faiss_store\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
